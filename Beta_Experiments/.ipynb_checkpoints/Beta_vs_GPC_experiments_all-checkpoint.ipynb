{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "\n",
    "- TODO: description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "py_file_location = '../utils'\n",
    "sys.path.append(os.path.abspath(py_file_location))\n",
    "py_file_location = '../models'\n",
    "sys.path.append(os.path.abspath(py_file_location))\n",
    "\n",
    "import classification_utils\n",
    "import classification_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fce59d32890>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 5 #1,2,3,4,5\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all datasets\n",
    "\n",
    "The four datasets we use are \n",
    "- EEG\n",
    "- HTRU2\n",
    "- MAGIC\n",
    "- MiniBoo\n",
    "All of them are UCI datasets that were already used for the Dirichlet GPC paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329.23</td>\n",
       "      <td>4009.23</td>\n",
       "      <td>4289.23</td>\n",
       "      <td>4148.21</td>\n",
       "      <td>4350.26</td>\n",
       "      <td>4586.15</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4641.03</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4238.46</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4635.90</td>\n",
       "      <td>4393.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4328.72</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4296.41</td>\n",
       "      <td>4155.90</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4630.77</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4235.38</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4632.31</td>\n",
       "      <td>4396.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4292.31</td>\n",
       "      <td>4151.28</td>\n",
       "      <td>4347.69</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4095.90</td>\n",
       "      <td>4627.69</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4244.10</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4398.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1        2        3        4        5        6        7   \\\n",
       "0  4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
       "1  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
       "2  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
       "3  4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
       "4  4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
       "\n",
       "        8        9        10       11       12       13  14  \n",
       "0  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85   0  \n",
       "1  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10   0  \n",
       "2  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23   0  \n",
       "3  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41   0  \n",
       "4  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load EEG dataset\n",
    "data_files = \"data/\"\n",
    "\n",
    "EEG_filename = \"EEG_Eye_State.csv\"\n",
    "EEG_df = pd.read_csv(data_files + EEG_filename, header=None)\n",
    "EEG_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1         2         3         4          5          6  \\\n",
       "0  140.562500  55.683782 -0.234571 -0.699648  3.199833  19.110426   7.975532   \n",
       "1  102.507812  58.882430  0.465318 -0.515088  1.677258  14.860146  10.576487   \n",
       "2  103.015625  39.341649  0.323328  1.051164  3.121237  21.744669   7.735822   \n",
       "3  136.750000  57.178449 -0.068415 -0.636238  3.642977  20.959280   6.896499   \n",
       "4   88.726562  40.672225  0.600866  1.123492  1.178930  11.468720  14.269573   \n",
       "\n",
       "            7  8  \n",
       "0   74.242225  0  \n",
       "1  127.393580  0  \n",
       "2   63.171909  0  \n",
       "3   53.593661  0  \n",
       "4  252.567306  0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load HTRU2 dataset\n",
    "HTRU2_filename = \"HTRU_2.csv\"\n",
    "HTRU2_df = pd.read_csv(data_files + HTRU2_filename, header=None)\n",
    "HTRU2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1       2       3       4         5        6        7   \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
       "\n",
       "        8         9   10  \n",
       "0  40.0920   81.8828   1  \n",
       "1   6.3609  205.2610   1  \n",
       "2  76.9600  256.7880   1  \n",
       "3  10.4490  116.7370   1  \n",
       "4   4.6480  356.4620   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load MAGIC dataset\n",
    "MAGIC_filename = \"magic04.csv\"\n",
    "MAGIC_df = pd.read_csv(data_files + MAGIC_filename, header=None)\n",
    "\n",
    "#map final column from g/h to 1/0\n",
    "MAGIC_df = MAGIC_df.replace({\"g\":1, \"h\":0})\n",
    "\n",
    "MAGIC_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.96113</td>\n",
       "      <td>0.384599</td>\n",
       "      <td>1087.1200</td>\n",
       "      <td>0.251748</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.116820</td>\n",
       "      <td>0.872463</td>\n",
       "      <td>3.11779</td>\n",
       "      <td>0.185689</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.7970</td>\n",
       "      <td>0.947933</td>\n",
       "      <td>2.29170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242451</td>\n",
       "      <td>0.184653</td>\n",
       "      <td>2.975180</td>\n",
       "      <td>0.016929</td>\n",
       "      <td>0.236594</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.84353</td>\n",
       "      <td>1.741840</td>\n",
       "      <td>101.6440</td>\n",
       "      <td>0.295625</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.130203</td>\n",
       "      <td>1.171860</td>\n",
       "      <td>0.885831</td>\n",
       "      <td>3.40604</td>\n",
       "      <td>0.207060</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.3280</td>\n",
       "      <td>3.938770</td>\n",
       "      <td>6.63478</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.160161</td>\n",
       "      <td>0.220539</td>\n",
       "      <td>0.792976</td>\n",
       "      <td>0.056713</td>\n",
       "      <td>0.198655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.88238</td>\n",
       "      <td>2.748180</td>\n",
       "      <td>88.5783</td>\n",
       "      <td>0.300086</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737055</td>\n",
       "      <td>0.677884</td>\n",
       "      <td>3.89686</td>\n",
       "      <td>0.093560</td>\n",
       "      <td>...</td>\n",
       "      <td>-88.3881</td>\n",
       "      <td>-0.793292</td>\n",
       "      <td>3.08822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124882</td>\n",
       "      <td>0.367171</td>\n",
       "      <td>6.016120</td>\n",
       "      <td>6.133560</td>\n",
       "      <td>0.255304</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.43173</td>\n",
       "      <td>1.948110</td>\n",
       "      <td>103.1530</td>\n",
       "      <td>0.264039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191277</td>\n",
       "      <td>1.177080</td>\n",
       "      <td>0.883820</td>\n",
       "      <td>3.27063</td>\n",
       "      <td>0.169655</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.1426</td>\n",
       "      <td>0.435008</td>\n",
       "      <td>4.61928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127263</td>\n",
       "      <td>0.172886</td>\n",
       "      <td>0.985063</td>\n",
       "      <td>0.212094</td>\n",
       "      <td>0.203885</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.75619</td>\n",
       "      <td>0.405642</td>\n",
       "      <td>63.6347</td>\n",
       "      <td>0.233746</td>\n",
       "      <td>0.011423</td>\n",
       "      <td>0.406455</td>\n",
       "      <td>1.089350</td>\n",
       "      <td>0.883967</td>\n",
       "      <td>3.29230</td>\n",
       "      <td>0.207975</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.1712</td>\n",
       "      <td>0.097014</td>\n",
       "      <td>4.57457</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.129168</td>\n",
       "      <td>-0.085241</td>\n",
       "      <td>0.886991</td>\n",
       "      <td>-0.020713</td>\n",
       "      <td>0.273904</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1          2         3         4         5         6   \\\n",
       "0  3.96113  0.384599  1087.1200  0.251748  0.015258  0.000000  1.116820   \n",
       "1  3.84353  1.741840   101.6440  0.295625  0.002525  0.130203  1.171860   \n",
       "2  6.88238  2.748180    88.5783  0.300086  0.002597  0.000000  0.737055   \n",
       "3  3.43173  1.948110   103.1530  0.264039  0.000000  0.191277  1.177080   \n",
       "4  2.75619  0.405642    63.6347  0.233746  0.011423  0.406455  1.089350   \n",
       "\n",
       "         7        8         9   ...       41        42       43        44  \\\n",
       "0  0.872463  3.11779  0.185689  ... -19.7970  0.947933  2.29170  0.000000   \n",
       "1  0.885831  3.40604  0.207060  ... -32.3280  3.938770  6.63478  0.002525   \n",
       "2  0.677884  3.89686  0.093560  ... -88.3881 -0.793292  3.08822  0.000000   \n",
       "3  0.883820  3.27063  0.169655  ... -24.1426  0.435008  4.61928  0.000000   \n",
       "4  0.883967  3.29230  0.207975  ... -21.1712  0.097014  4.57457  0.001038   \n",
       "\n",
       "         45        46        47        48        49   50  \n",
       "0  0.242451  0.184653  2.975180  0.016929  0.236594  0.0  \n",
       "1  0.160161  0.220539  0.792976  0.056713  0.198655  1.0  \n",
       "2  0.124882  0.367171  6.016120  6.133560  0.255304  1.0  \n",
       "3  0.127263  0.172886  0.985063  0.212094  0.203885  1.0  \n",
       "4  0.129168 -0.085241  0.886991 -0.020713  0.273904  0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load Miniboo dataset\n",
    "train_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "# IMPORTANT: there are 10 splits for train and test. Each of them has 120K training points ... \n",
    "# However, the k-means clustering algorithm may take a while if we load all of them\n",
    "# Therefore, it might make more sense to just choose 1 split for the beginning.\n",
    "for i in range(1): #10\n",
    "    i_ = i+1\n",
    "    # load training\n",
    "    MiniBoo_filename_train = \"MiniBoo_splits/train{:02d}.txt\".format(i_)\n",
    "    MiniBoo_df_train = pd.read_csv(data_files + MiniBoo_filename_train, header=None)\n",
    "    train_dfs.append(MiniBoo_df_train)\n",
    "    # load test\n",
    "    MiniBoo_filename_test = \"MiniBoo_splits/test{:02d}.txt\".format(i_)\n",
    "    MiniBoo_df_test = pd.read_csv(data_files + MiniBoo_filename_test, header=None)\n",
    "    test_dfs.append(MiniBoo_df_test)\n",
    "    \n",
    "MiniBoo_train_df = pd.concat(train_dfs)\n",
    "MiniBoo_test_df = pd.concat(test_dfs)\n",
    "MiniBoo_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize & Create test train splits\n",
    "\n",
    "As in the Dirichlet GPC paper, we use the following test-train splits\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10980, 14)\n",
      "(4000, 14)\n",
      "(10980,)\n",
      "(4000,)\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# make test-train split for EEG\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_EEG = EEG_df.values[:,:-1]\n",
    "Y_EEG = EEG_df.values[:,-1]\n",
    "NUM_TRAINING_POINTS_EEG=10980\n",
    "NUM_TEST_POINTS_EEG=4000\n",
    "\n",
    "# Normalize data\n",
    "X_EEG = classification_utils.standardise(X_EEG)\n",
    "#X_EEG = classification_utils.normalise_minusonetoone(X_EEG)\n",
    "\n",
    "# The original paper chose 10980 training points and 4000 test points\n",
    "test_size_EEG = NUM_TEST_POINTS_EEG/(NUM_TRAINING_POINTS_EEG+NUM_TEST_POINTS_EEG)\n",
    "X_EEG_train, X_EEG_test, y_EEG_train, y_EEG_test = train_test_split(X_EEG, Y_EEG, test_size=test_size_EEG, random_state=seed)\n",
    "print(np.shape(X_EEG_train))\n",
    "print(np.shape(X_EEG_test))\n",
    "print(np.shape(y_EEG_train))\n",
    "print(np.shape(y_EEG_test))\n",
    "X_EEG_train, X_EEG_test, y_EEG_train, y_EEG_test = torch.tensor(X_EEG_train).float(), torch.tensor(X_EEG_test).float(), \\\n",
    "                                                   torch.tensor(y_EEG_train).long(), torch.tensor(y_EEG_test).long()\n",
    "print(y_EEG_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12898, 8)\n",
      "(5000, 8)\n",
      "(12898,)\n",
      "(5000,)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# make test-train split for HTRU2\n",
    "\n",
    "X_HTRU2 = HTRU2_df.values[:,:-1]\n",
    "Y_HTRU2 = HTRU2_df.values[:,-1]\n",
    "NUM_TRAINING_POINTS_HTRU2=12898\n",
    "NUM_TEST_POINTS_HTRU2=5000\n",
    "\n",
    "# Normalize data\n",
    "X_HTRU2 = classification_utils.standardise(X_HTRU2)\n",
    "#X_HTRU2 = classification_utils.normalise_minusonetoone(X_HTRU2)\n",
    "\n",
    "test_size_HTRU2 = NUM_TEST_POINTS_HTRU2/(NUM_TRAINING_POINTS_HTRU2+NUM_TEST_POINTS_HTRU2)\n",
    "X_HTRU2_train, X_HTRU2_test, y_HTRU2_train, y_HTRU2_test = train_test_split(X_HTRU2, Y_HTRU2, test_size=test_size_HTRU2, random_state=seed)\n",
    "print(np.shape(X_HTRU2_train))\n",
    "print(np.shape(X_HTRU2_test))\n",
    "print(np.shape(y_HTRU2_train))\n",
    "print(np.shape(y_HTRU2_test))\n",
    "X_HTRU2_train, X_HTRU2_test, y_HTRU2_train, y_HTRU2_test = torch.tensor(X_HTRU2_train).float(), torch.tensor(X_HTRU2_test).float(), \\\n",
    "                                                   torch.tensor(y_HTRU2_train).long(), torch.tensor(y_HTRU2_test).long()\n",
    "print(y_HTRU2_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14020, 10)\n",
      "(5000, 10)\n",
      "(14020,)\n",
      "(5000,)\n",
      "tensor([1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# make test-train split for MAGIC\n",
    "\n",
    "X_MAGIC = MAGIC_df.values[:,:-1]\n",
    "Y_MAGIC = MAGIC_df.values[:,-1]\n",
    "NUM_TRAINING_POINTS_MAGIC=14020\n",
    "NUM_TEST_POINTS_MAGIC=5000\n",
    "\n",
    "# Normalize data\n",
    "X_MAGIC = classification_utils.standardise(X_MAGIC)\n",
    "#X_MAGIC = classification_utils.normalise_minusonetoone(X_MAGIC)\n",
    "\n",
    "test_size_MAGIC = NUM_TEST_POINTS_MAGIC/(NUM_TRAINING_POINTS_MAGIC+NUM_TEST_POINTS_MAGIC)\n",
    "X_MAGIC_train, X_MAGIC_test, y_MAGIC_train, y_MAGIC_test = train_test_split(X_MAGIC, Y_MAGIC, test_size=test_size_MAGIC, random_state=seed)\n",
    "print(np.shape(X_MAGIC_train))\n",
    "print(np.shape(X_MAGIC_test))\n",
    "print(np.shape(y_MAGIC_train))\n",
    "print(np.shape(y_MAGIC_test))\n",
    "X_MAGIC_train, X_MAGIC_test, y_MAGIC_train, y_MAGIC_test = torch.tensor(X_MAGIC_train).float(), torch.tensor(X_MAGIC_test).float(), \\\n",
    "                                                   torch.tensor(y_MAGIC_train).long(), torch.tensor(y_MAGIC_test).long()\n",
    "print(y_MAGIC_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 50)\n",
      "(5000, 50)\n",
      "(20000,)\n",
      "(5000,)\n",
      "tensor([1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# make test-train split for MiniBoo\n",
    "\n",
    "X_MiniBoo_train = MiniBoo_train_df.values[:,:-1]\n",
    "y_MiniBoo_train = MiniBoo_train_df.values[:,-1]\n",
    "X_MiniBoo_test = MiniBoo_test_df.values[:,:-1]\n",
    "y_MiniBoo_test = MiniBoo_test_df.values[:,-1]\n",
    "\n",
    "# IMPORTANT: the miniboo dataset is kinda large (120K datapoints)\n",
    "# Therefore, we'll prune it when testing the code.\n",
    "X_MiniBoo_train = X_MiniBoo_train[:20000,:]\n",
    "y_MiniBoo_train = y_MiniBoo_train[:20000]\n",
    "X_MiniBoo_test = X_MiniBoo_test[:5000,:]\n",
    "y_MiniBoo_test = y_MiniBoo_test[:5000]\n",
    "\n",
    "# Normalize data\n",
    "X_MiniBoo_train = classification_utils.standardise(X_MiniBoo_train)\n",
    "X_MiniBoo_test = classification_utils.standardise(X_MiniBoo_test)\n",
    "#X_MiniBoo = classification_utils.normalise_minusonetoone(X_MiniBoo)\n",
    "\n",
    "print(np.shape(X_MiniBoo_train))\n",
    "print(np.shape(X_MiniBoo_test))\n",
    "print(np.shape(y_MiniBoo_train))\n",
    "print(np.shape(y_MiniBoo_test))\n",
    "X_MiniBoo_train, X_MiniBoo_test, y_MiniBoo_train, y_MiniBoo_test = torch.tensor(X_MiniBoo_train).float(), torch.tensor(X_MiniBoo_test).float(), \\\n",
    "                                                   torch.tensor(y_MiniBoo_train).long(), torch.tensor(y_MiniBoo_test).long()\n",
    "print(y_MiniBoo_test[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create inducing points\n",
    "\n",
    "As in the Dirichlet GPC paper, we use the following number of inducing points\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INDUCING_POINTS_EEG=200\n",
    "NUM_INDUCING_POINTS_HTRU2=200\n",
    "NUM_INDUCING_POINTS_MAGIC=200\n",
    "NUM_INDUCING_POINTS_MiniBoo=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.0884e-02,  2.3213e+00,  8.2130e-01,  4.0649e-03,  6.7907e-02,\n",
      "         -9.0890e-03, -8.8377e-03, -1.0732e+00, -2.1053e-02, -2.1646e-01,\n",
      "          5.3204e-01,  9.0719e-01,  2.0520e-02,  1.2531e-02],\n",
      "        [-3.4462e-03, -8.7130e-01, -9.7336e-03, -1.3925e-02, -2.8646e-01,\n",
      "         -1.5404e-02, -3.4864e-03,  2.9466e-02, -4.4921e-03,  3.8985e-01,\n",
      "          1.1159e+00,  5.6152e-01,  4.4710e-02,  2.5703e-04]]) tensor([0, 1])\n",
      "tensor([[ 5.0884e-02,  2.3213e+00,  8.2130e-01,  4.0649e-03,  6.7907e-02,\n",
      "         -9.0890e-03, -8.8377e-03, -1.0732e+00, -2.1053e-02, -2.1646e-01,\n",
      "          5.3204e-01,  9.0719e-01,  2.0520e-02,  1.2531e-02],\n",
      "        [-3.4462e-03, -8.7130e-01, -9.7336e-03, -1.3925e-02, -2.8646e-01,\n",
      "         -1.5404e-02, -3.4864e-03,  2.9466e-02, -4.4921e-03,  3.8985e-01,\n",
      "          1.1159e+00,  5.6152e-01,  4.4710e-02,  2.5703e-04]]) tensor([12.0100, 36.0100]) tensor([18.0100,  2.0100])\n"
     ]
    }
   ],
   "source": [
    "### EEG\n",
    "\n",
    "## choose random inducing points\n",
    "#X_EEG_train_induced, y_EEG_train_induced = classification_utils.random_inducing_points(X_EEG_train, y_EEG_train, NUM_INDUCING_POINTS_EEG)\n",
    "\n",
    "## use kmeans for inducing points\n",
    "X_EEG_train_induced, y_EEG_train_induced = classification_utils.k_means_inducing_points(X_EEG_train, y_EEG_train, NUM_INDUCING_POINTS_EEG)\n",
    "print(X_EEG_train_induced[:2], y_EEG_train_induced[:2])\n",
    "\n",
    "# use the conjugacy of the Beta to create better inducing points\n",
    "X_EEG_train_induced, y_EEG_train_induced_alphas, y_EEG_train_induced_betas = classification_utils.k_means_inducing_points_LM_beta(X_EEG_train, y_EEG_train, NUM_INDUCING_POINTS_EEG)\n",
    "print(X_EEG_train_induced[:2], y_EEG_train_induced_alphas[:2], y_EEG_train_induced_betas[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3313,  1.4238, -0.2694, -0.3310, -0.3440, -0.4739,  0.2409, -0.0279],\n",
      "        [-2.1703, -0.7639,  2.2148,  1.1235,  3.4244,  2.6550, -1.8571, -0.9940]]) tensor([0, 1])\n",
      "tensor([[ 0.3313,  1.4238, -0.2694, -0.3310, -0.3440, -0.4739,  0.2409, -0.0279],\n",
      "        [-2.1703, -0.7639,  2.2148,  1.1235,  3.4244,  2.6550, -1.8571, -0.9940]]) tensor([ 2.0100, 16.0100]) tensor([126.0100,   2.0100])\n"
     ]
    }
   ],
   "source": [
    "### HTRU2\n",
    "\n",
    "## choose random inducing points\n",
    "#X_HTRU2_train_induced, y_HTRU2_train_induced = classification_utils.random_inducing_points(X_HTRU2_train, y_HTRU2_train, NUM_INDUCING_POINTS_HTRU2)\n",
    "\n",
    "## use kmeans for inducing points\n",
    "X_HTRU2_train_induced, y_HTRU2_train_induced = classification_utils.k_means_inducing_points(X_HTRU2_train, y_HTRU2_train, NUM_INDUCING_POINTS_HTRU2)\n",
    "print(X_HTRU2_train_induced[:2], y_HTRU2_train_induced[:2])\n",
    "\n",
    "# use the conjugacy of the Beta to create better inducing points\n",
    "X_HTRU2_train_induced, y_HTRU2_train_induced_alphas, y_HTRU2_train_induced_betas = classification_utils.k_means_inducing_points_LM_beta(X_HTRU2_train, y_HTRU2_train, NUM_INDUCING_POINTS_HTRU2)\n",
    "print(X_HTRU2_train_induced[:2], y_HTRU2_train_induced_alphas[:2], y_HTRU2_train_induced_betas[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7744, -0.8129, -1.6624,  1.8160,  1.4872,  0.0502, -0.0455, -0.2872,\n",
      "         -0.6087, -0.8407],\n",
      "        [-0.2652, -0.3498,  0.1991, -0.5122, -0.6394,  0.3475,  0.3502, -0.5967,\n",
      "         -1.0236,  0.0660]]) tensor([1, 1])\n",
      "tensor([[-0.7744, -0.8129, -1.6624,  1.8160,  1.4872,  0.0502, -0.0455, -0.2872,\n",
      "         -0.6087, -0.8407],\n",
      "        [-0.2652, -0.3498,  0.1991, -0.5122, -0.6394,  0.3475,  0.3502, -0.5967,\n",
      "         -1.0236,  0.0660]]) tensor([116.0100, 190.0100]) tensor([23.0100,  9.0100])\n"
     ]
    }
   ],
   "source": [
    "### MAGIC\n",
    "\n",
    "## choose random inducing points\n",
    "#X_MAGIC_train_induced, y_MAGIC_train_induced = classification_utils.random_inducing_points(X_MAGIC_train, y_MAGIC_train, NUM_INDUCING_POINTS_MAGIC)\n",
    "\n",
    "## use kmeans for inducing points\n",
    "X_MAGIC_train_induced, y_MAGIC_train_induced = classification_utils.k_means_inducing_points(X_MAGIC_train, y_MAGIC_train, NUM_INDUCING_POINTS_MAGIC)\n",
    "print(X_MAGIC_train_induced[:2], y_MAGIC_train_induced[:2])\n",
    "\n",
    "# use the conjugacy of the Beta to create better inducing points\n",
    "X_MAGIC_train_induced, y_MAGIC_train_induced_alphas, y_MAGIC_train_induced_betas = classification_utils.k_means_inducing_points_LM_beta(X_MAGIC_train, y_MAGIC_train, NUM_INDUCING_POINTS_MAGIC)\n",
    "print(X_MAGIC_train_induced[:2], y_MAGIC_train_induced_alphas[:2], y_MAGIC_train_induced_betas[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.3033e-02,  5.3380e-02, -1.3805e-02,  6.1487e-02,  6.2018e-02,\n",
      "          6.1813e-02,  6.2235e-02,  6.3347e-02,  5.6586e-02,  6.1945e-02,\n",
      "          5.7336e-02, -9.7243e-01,  6.7089e-02,  5.7450e-02,  7.2649e-02,\n",
      "          2.0188e-01,  6.3359e-02, -5.2585e-02,  6.1781e-02,  3.9299e-02,\n",
      "          7.9400e-02,  6.3935e-02,  5.9228e-01,  5.0811e-02,  6.2558e-02,\n",
      "          8.1421e-02,  7.4281e-01,  6.1410e-02,  6.1776e-02,  6.3557e-02,\n",
      "          3.8173e-02,  6.5781e-02,  5.8706e-02,  9.4155e-01,  6.2700e-02,\n",
      "          6.0825e-02,  5.7044e-02,  6.0110e-02,  6.4846e-02,  6.2386e-02,\n",
      "         -1.0134e-01,  4.8157e-01,  6.4993e-02,  7.1605e-03,  6.2020e-02,\n",
      "          6.2424e-02,  6.9011e-02,  4.6987e-02,  4.6492e-02,  6.2751e-02],\n",
      "        [-1.6083e+01, -1.6084e+01, -5.3979e+00, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -8.5687e+00, -1.6085e+01, -1.6085e+01, -1.6084e+01,\n",
      "         -2.9299e+00, -1.6085e+01, -1.4670e+01, -1.6085e+01, -9.0825e+00,\n",
      "         -1.6078e+01, -1.6085e+01, -9.8232e+00, -1.6078e+01, -1.6085e+01,\n",
      "         -1.6076e+01, -1.0951e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6074e+01, -1.6085e+01, -1.6084e+01, -1.0636e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6084e+01, -1.6083e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.4680e+01, -1.4053e+01, -1.6082e+01, -1.6042e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6084e+01, -1.6078e+01, -1.6077e+01, -1.6085e+01]]) tensor([1, 1])\n",
      "tensor([[ 5.3033e-02,  5.3380e-02, -1.3805e-02,  6.1487e-02,  6.2018e-02,\n",
      "          6.1813e-02,  6.2235e-02,  6.3347e-02,  5.6586e-02,  6.1945e-02,\n",
      "          5.7336e-02, -9.7243e-01,  6.7089e-02,  5.7450e-02,  7.2649e-02,\n",
      "          2.0188e-01,  6.3359e-02, -5.2585e-02,  6.1781e-02,  3.9299e-02,\n",
      "          7.9400e-02,  6.3935e-02,  5.9228e-01,  5.0811e-02,  6.2558e-02,\n",
      "          8.1421e-02,  7.4281e-01,  6.1410e-02,  6.1776e-02,  6.3557e-02,\n",
      "          3.8173e-02,  6.5781e-02,  5.8706e-02,  9.4155e-01,  6.2700e-02,\n",
      "          6.0825e-02,  5.7044e-02,  6.0110e-02,  6.4846e-02,  6.2386e-02,\n",
      "         -1.0134e-01,  4.8157e-01,  6.4993e-02,  7.1605e-03,  6.2020e-02,\n",
      "          6.2424e-02,  6.9011e-02,  4.6987e-02,  4.6492e-02,  6.2751e-02],\n",
      "        [-1.6083e+01, -1.6084e+01, -5.3979e+00, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -8.5687e+00, -1.6085e+01, -1.6085e+01, -1.6084e+01,\n",
      "         -2.9299e+00, -1.6085e+01, -1.4670e+01, -1.6085e+01, -9.0825e+00,\n",
      "         -1.6078e+01, -1.6085e+01, -9.8232e+00, -1.6078e+01, -1.6085e+01,\n",
      "         -1.6076e+01, -1.0951e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6074e+01, -1.6085e+01, -1.6084e+01, -1.0636e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6084e+01, -1.6083e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.4680e+01, -1.4053e+01, -1.6082e+01, -1.6042e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6084e+01, -1.6078e+01, -1.6077e+01, -1.6085e+01]]) tensor([42.0100, 76.0100]) tensor([20.0100,  1.0100])\n"
     ]
    }
   ],
   "source": [
    "### MiniBoo\n",
    "\n",
    "## choose random inducing points\n",
    "#X_MiniBoo_train_induced, y_MiniBoo_train_induced = classification_utils.random_inducing_points(X_MiniBoo_train, y_MiniBoo_train, NUM_INDUCING_POINTS_MiniBoo)\n",
    "\n",
    "## use kmeans for inducing points\n",
    "X_MiniBoo_train_induced, y_MiniBoo_train_induced = classification_utils.k_means_inducing_points(X_MiniBoo_train, y_MiniBoo_train, NUM_INDUCING_POINTS_MiniBoo)\n",
    "print(X_MiniBoo_train_induced[:2], y_MiniBoo_train_induced[:2])\n",
    "\n",
    "# use the conjugacy of the Beta to create better inducing points\n",
    "X_MiniBoo_train_induced, y_MiniBoo_train_induced_alphas, y_MiniBoo_train_induced_betas = classification_utils.k_means_inducing_points_LM_beta(X_MiniBoo_train, y_MiniBoo_train, NUM_INDUCING_POINTS_MiniBoo)\n",
    "print(X_MiniBoo_train_induced[:2], y_MiniBoo_train_induced_alphas[:2], y_MiniBoo_train_induced_betas[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for GPC & LB(Beta)+GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTHSCALES = [0.01, 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose lengthscale with CV\n",
    "NUM_ITER_EEG = 200\n",
    "LR_EEG = 0.1\n",
    "\"\"\"\n",
    "res_EEG = classification_models.select_init_lengthscale_with_CV(X_EEG_train, y_EEG_train, mode=\"DGP\",\n",
    "                                    num_inducing_points=NUM_INDUCING_POINTS_EEG, \n",
    "                                    learn_noise=True, num_iter=NUM_ITER_EEG, lr=LR_EEG,\n",
    "                                    lengthscales=LENGTHSCALES)\n",
    "print(res_EEG)    \n",
    "classification_utils.plot_res(res_EEG)\n",
    "\"\"\"\n",
    "\n",
    "INIT_LENGHTSCALE_EEG = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 5.967   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 5.355   lengthscale: 1.102   noise: 2.084\n",
      "Iter 41/200 - Loss: 5.152   lengthscale: 0.907   noise: 3.340\n",
      "Iter 61/200 - Loss: 5.130   lengthscale: 0.989   noise: 3.917\n",
      "Iter 81/200 - Loss: 5.127   lengthscale: 1.017   noise: 4.145\n",
      "Iter 101/200 - Loss: 5.127   lengthscale: 1.037   noise: 4.224\n",
      "Iter 121/200 - Loss: 5.126   lengthscale: 1.048   noise: 4.244\n",
      "Iter 141/200 - Loss: 5.126   lengthscale: 1.052   noise: 4.241\n",
      "Iter 161/200 - Loss: 5.126   lengthscale: 1.056   noise: 4.228\n",
      "Iter 181/200 - Loss: 5.126   lengthscale: 1.059   noise: 4.212\n",
      "(0.6467499732971191, 0.7012051939964294, 0.12777778506278992)\n"
     ]
    }
   ],
   "source": [
    "### run Dirichlet GPC\n",
    "\n",
    "DGP_model, DGP_likelihood = classification_models.create_DGP_model(X_EEG_train_induced, y_EEG_train_induced,\n",
    "                                        init_lengthscale=INIT_LENGHTSCALE_EEG, learn_additional_noise=True)\n",
    "DGP_model, DGP_likelihood = classification_models.train_DGP_model(X_EEG_train_induced,\n",
    "                                DGP_model, DGP_likelihood, num_iter=NUM_ITER_EEG, lr=LR_EEG, report_iter=NUM_ITER_EEG//10)\n",
    "EEG_DGP_res = classification_models.evaluate_DGP(DGP_model, DGP_likelihood, X_EEG_test, y_EEG_test)\n",
    "print(EEG_DGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 3.040   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.966   lengthscale: 1.035   noise: 2.124\n",
      "Iter 41/200 - Loss: 2.933   lengthscale: 1.307   noise: 3.780\n",
      "Iter 61/200 - Loss: 2.921   lengthscale: 1.448   noise: 5.039\n",
      "Iter 81/200 - Loss: 2.917   lengthscale: 1.507   noise: 5.896\n",
      "Iter 101/200 - Loss: 2.915   lengthscale: 1.562   noise: 6.477\n",
      "Iter 121/200 - Loss: 2.914   lengthscale: 1.605   noise: 6.876\n",
      "Iter 141/200 - Loss: 2.913   lengthscale: 1.639   noise: 7.149\n",
      "Iter 161/200 - Loss: 2.913   lengthscale: 1.665   noise: 7.332\n",
      "Iter 181/200 - Loss: 2.913   lengthscale: 1.685   noise: 7.451\n",
      "(0.606249988079071, 0.7131885290145874, 0.14380775392055511)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP vanilla\n",
    "y_EEG_train_induced_mu, y_EEG_train_induced_var = classification_models.transform_y_beta_LM(y_EEG_train_induced)\n",
    "LMGP_model_EEG, LMGP_likelihood_EEG = classification_models.create_LM_beta_GP_model(X_EEG_train_induced, y_EEG_train_induced_mu,\n",
    "                                                y_EEG_train_induced_var, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_EEG)\n",
    "LMGP_model_EEG, LMGP_likelihood_EEG = classification_models.train_LM_beta_GP_model(X_EEG_train_induced, y_EEG_train_induced_mu,\n",
    "                    LMGP_model_EEG, LMGP_likelihood_EEG, num_iter=NUM_ITER_EEG, lr=LR_EEG, report_iter=NUM_ITER_EEG//10)\n",
    "EEG_LMGP_res = classification_models.evaluate_LM_beta_GP(LMGP_model_EEG, LMGP_likelihood_EEG, X_EEG_test, y_EEG_test)\n",
    "print(EEG_LMGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.350   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.278   lengthscale: 1.174   noise: 1.206\n",
      "Iter 41/200 - Loss: 2.211   lengthscale: 0.792   noise: 0.435\n",
      "Iter 61/200 - Loss: 2.179   lengthscale: 0.729   noise: 0.131\n",
      "Iter 81/200 - Loss: 2.169   lengthscale: 0.730   noise: 0.083\n",
      "Iter 101/200 - Loss: 2.164   lengthscale: 0.748   noise: 0.071\n",
      "Iter 121/200 - Loss: 2.161   lengthscale: 0.760   noise: 0.066\n",
      "Iter 141/200 - Loss: 2.159   lengthscale: 0.771   noise: 0.064\n",
      "Iter 161/200 - Loss: 2.158   lengthscale: 0.781   noise: 0.063\n",
      "Iter 181/200 - Loss: 2.157   lengthscale: 0.789   noise: 0.063\n",
      "(0.7127500176429749, 0.5398080348968506, 0.021660421043634415)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP with conjugacy information\n",
    "\n",
    "train_mu_LB_con_EEG, train_var_LB_con_EEG = classification_models.LM_beta(y_EEG_train_induced_alphas, y_EEG_train_induced_betas)\n",
    "LMGP_model_con_EEG, LMGP_likelihood_con_EEG = classification_models.create_LM_beta_GP_model(X_EEG_train_induced, train_mu_LB_con_EEG,\n",
    "                                                train_var_LB_con_EEG, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_EEG)\n",
    "LMGP_model_con_EEG, LMGP_likelihood_con_EEG = classification_models.train_LM_beta_GP_model(X_EEG_train_induced, train_mu_LB_con_EEG,\n",
    "                LMGP_model_con_EEG, LMGP_likelihood_con_EEG, num_iter=NUM_ITER_EEG, lr=LR_EEG, report_iter=NUM_ITER_EEG//10)\n",
    "\n",
    "EEG_LMGP_con_res = classification_models.evaluate_LM_beta_GP(LMGP_model_con_EEG, LMGP_likelihood_con_EEG, X_EEG_test, y_EEG_test)\n",
    "print(EEG_LMGP_con_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTRU2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose lengthscale with CV\n",
    "NUM_ITER_HTRU2 = 200\n",
    "LR_HTRU2 = 0.1\n",
    "\"\"\"\n",
    "res_HTRU2 = classification_models.select_init_lengthscale_with_CV(X_HTRU2_train, y_HTRU2_train, mode=\"DGP\",\n",
    "                                    num_inducing_points=NUM_INDUCING_POINTS_HTRU2, \n",
    "                                    learn_noise=True, num_iter=NUM_ITER_HTRU2, lr=LR_HTRU2,\n",
    "                                    lengthscales=LENGTHSCALES)\n",
    "print(res_HTRU2)    \n",
    "classification_utils.plot_res(res_HTRU2)\n",
    "\"\"\"\n",
    "\n",
    "INIT_LENGHTSCALE_HTRU2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 4.444   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 3.501   lengthscale: 3.426   noise: 0.159\n",
      "Iter 41/200 - Loss: 3.397   lengthscale: 3.851   noise: 0.115\n",
      "Iter 61/200 - Loss: 3.368   lengthscale: 3.877   noise: 0.091\n",
      "Iter 81/200 - Loss: 3.356   lengthscale: 3.854   noise: 0.055\n",
      "Iter 101/200 - Loss: 3.349   lengthscale: 3.871   noise: 0.039\n",
      "Iter 121/200 - Loss: 3.345   lengthscale: 3.922   noise: 0.031\n",
      "Iter 141/200 - Loss: 3.343   lengthscale: 3.976   noise: 0.027\n",
      "Iter 161/200 - Loss: 3.341   lengthscale: 4.021   noise: 0.024\n",
      "Iter 181/200 - Loss: 3.339   lengthscale: 4.061   noise: 0.022\n",
      "(0.9782000184059143, 0.07795679569244385, 0.03839163854718208)\n"
     ]
    }
   ],
   "source": [
    "### run Dirichlet GPC\n",
    "\n",
    "DGP_model, DGP_likelihood = classification_models.create_DGP_model(X_HTRU2_train_induced, y_HTRU2_train_induced,\n",
    "                                        init_lengthscale=INIT_LENGHTSCALE_HTRU2, learn_additional_noise=True)\n",
    "DGP_model, DGP_likelihood = classification_models.train_DGP_model(X_HTRU2_train_induced,\n",
    "                                DGP_model, DGP_likelihood, num_iter=NUM_ITER_HTRU2, lr=LR_HTRU2, report_iter=NUM_ITER_HTRU2//10)\n",
    "HTRU2_DGP_res = classification_models.evaluate_DGP(DGP_model, DGP_likelihood, X_HTRU2_test, y_HTRU2_test)\n",
    "print(HTRU2_DGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.599   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.381   lengthscale: 3.525   noise: 0.137\n",
      "Iter 41/200 - Loss: 2.347   lengthscale: 4.105   noise: 0.042\n",
      "Iter 61/200 - Loss: 2.336   lengthscale: 4.172   noise: 0.022\n",
      "Iter 81/200 - Loss: 2.330   lengthscale: 4.140   noise: 0.015\n",
      "Iter 101/200 - Loss: 2.326   lengthscale: 4.136   noise: 0.012\n",
      "Iter 121/200 - Loss: 2.324   lengthscale: 4.165   noise: 0.009\n",
      "Iter 141/200 - Loss: 2.322   lengthscale: 4.205   noise: 0.008\n",
      "Iter 161/200 - Loss: 2.321   lengthscale: 4.244   noise: 0.006\n",
      "Iter 181/200 - Loss: 2.319   lengthscale: 4.280   noise: 0.005\n",
      "(0.9768000245094299, 0.0793921947479248, 0.039690300822257996)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP vanilla\n",
    "y_HTRU2_train_induced_mu, y_HTRU2_train_induced_var = classification_models.transform_y_beta_LM(y_HTRU2_train_induced)\n",
    "LMGP_model_HTRU2, LMGP_likelihood_HTRU2 = classification_models.create_LM_beta_GP_model(X_HTRU2_train_induced, y_HTRU2_train_induced_mu,\n",
    "                                                y_HTRU2_train_induced_var, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_HTRU2)\n",
    "LMGP_model_HTRU2, LMGP_likelihood_HTRU2 = classification_models.train_LM_beta_GP_model(X_HTRU2_train_induced, y_HTRU2_train_induced_mu,\n",
    "                    LMGP_model_HTRU2, LMGP_likelihood_HTRU2, num_iter=NUM_ITER_HTRU2, lr=LR_HTRU2, report_iter=NUM_ITER_HTRU2//10)\n",
    "HTRU2_LMGP_res = classification_models.evaluate_LM_beta_GP(LMGP_model_HTRU2, LMGP_likelihood_HTRU2, X_HTRU2_test, y_HTRU2_test)\n",
    "print(HTRU2_LMGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.620   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.252   lengthscale: 3.407   noise: 0.161\n",
      "Iter 41/200 - Loss: 2.191   lengthscale: 3.578   noise: 0.088\n",
      "Iter 61/200 - Loss: 2.163   lengthscale: 3.290   noise: 0.066\n",
      "Iter 81/200 - Loss: 2.149   lengthscale: 3.210   noise: 0.045\n",
      "Iter 101/200 - Loss: 2.139   lengthscale: 3.267   noise: 0.032\n",
      "Iter 121/200 - Loss: 2.132   lengthscale: 3.289   noise: 0.024\n",
      "Iter 141/200 - Loss: 2.127   lengthscale: 3.308   noise: 0.019\n",
      "Iter 161/200 - Loss: 2.123   lengthscale: 3.335   noise: 0.016\n",
      "Iter 181/200 - Loss: 2.119   lengthscale: 3.358   noise: 0.013\n",
      "(0.9796000123023987, 0.07123546302318573, 0.04246756061911583)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP with conjugacy information\n",
    "\n",
    "train_mu_LB_con_HTRU2, train_var_LB_con_HTRU2 = classification_models.LM_beta(y_HTRU2_train_induced_alphas, y_HTRU2_train_induced_betas)\n",
    "LMGP_model_con_HTRU2, LMGP_likelihood_con_HTRU2 = classification_models.create_LM_beta_GP_model(X_HTRU2_train_induced, train_mu_LB_con_HTRU2,\n",
    "                                                train_var_LB_con_HTRU2, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_HTRU2)\n",
    "LMGP_model_con_HTRU2, LMGP_likelihood_con_HTRU2 = classification_models.train_LM_beta_GP_model(X_HTRU2_train_induced, train_mu_LB_con_HTRU2,\n",
    "                LMGP_model_con_HTRU2, LMGP_likelihood_con_HTRU2, num_iter=NUM_ITER_HTRU2, lr=LR_HTRU2, report_iter=NUM_ITER_HTRU2//10)\n",
    "\n",
    "HTRU2_LMGP_con_res = classification_models.evaluate_LM_beta_GP(LMGP_model_con_HTRU2, LMGP_likelihood_con_HTRU2, X_HTRU2_test, y_HTRU2_test)\n",
    "print(HTRU2_LMGP_con_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose lengthscale with CV\n",
    "NUM_ITER_MAGIC = 200\n",
    "LR_MAGIC = 0.1\n",
    "\"\"\"\n",
    "res_MAGIC = classification_models.select_init_lengthscale_with_CV(X_MAGIC_train, y_MAGIC_train, mode=\"DGP\",\n",
    "                                    num_inducing_points=NUM_INDUCING_POINTS_MAGIC, \n",
    "                                    learn_noise=True, num_iter=NUM_ITER_MAGIC, lr=LR_MAGIC,\n",
    "                                    lengthscales=LENGTHSCALES)\n",
    "print(res_MAGIC)    \n",
    "classification_utils.plot_res(res_MAGIC)\n",
    "\"\"\"\n",
    "\n",
    "INIT_LENGHTSCALE_MAGIC = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 5.675   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 4.719   lengthscale: 3.013   noise: 1.796\n",
      "Iter 41/200 - Loss: 4.619   lengthscale: 3.311   noise: 1.784\n",
      "Iter 61/200 - Loss: 4.587   lengthscale: 3.351   noise: 1.436\n",
      "Iter 81/200 - Loss: 4.569   lengthscale: 3.196   noise: 1.342\n",
      "Iter 101/200 - Loss: 4.555   lengthscale: 3.070   noise: 1.307\n",
      "Iter 121/200 - Loss: 4.545   lengthscale: 2.936   noise: 1.245\n",
      "Iter 141/200 - Loss: 4.538   lengthscale: 2.823   noise: 1.188\n",
      "Iter 161/200 - Loss: 4.533   lengthscale: 2.735   noise: 1.152\n",
      "Iter 181/200 - Loss: 4.531   lengthscale: 2.687   noise: 1.131\n",
      "(0.795799970626831, 0.5362366437911987, 0.10130868852138519)\n"
     ]
    }
   ],
   "source": [
    "### run Dirichlet GPC\n",
    "\n",
    "DGP_model, DGP_likelihood = classification_models.create_DGP_model(X_MAGIC_train_induced, y_MAGIC_train_induced,\n",
    "                                        init_lengthscale=INIT_LENGHTSCALE_MAGIC, learn_additional_noise=True)\n",
    "DGP_model, DGP_likelihood = classification_models.train_DGP_model(X_MAGIC_train_induced,\n",
    "                                DGP_model, DGP_likelihood, num_iter=NUM_ITER_MAGIC, lr=LR_MAGIC, report_iter=NUM_ITER_MAGIC//10)\n",
    "MAGIC_DGP_res = classification_models.evaluate_DGP(DGP_model, DGP_likelihood, X_MAGIC_test, y_MAGIC_test)\n",
    "print(MAGIC_DGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.925   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.733   lengthscale: 3.253   noise: 1.609\n",
      "Iter 41/200 - Loss: 2.684   lengthscale: 2.736   noise: 0.876\n",
      "Iter 61/200 - Loss: 2.667   lengthscale: 2.743   noise: 0.263\n",
      "Iter 81/200 - Loss: 2.659   lengthscale: 2.752   noise: 0.116\n",
      "Iter 101/200 - Loss: 2.656   lengthscale: 2.794   noise: 0.072\n",
      "Iter 121/200 - Loss: 2.653   lengthscale: 2.815   noise: 0.052\n",
      "Iter 141/200 - Loss: 2.652   lengthscale: 2.845   noise: 0.040\n",
      "Iter 161/200 - Loss: 2.651   lengthscale: 2.869   noise: 0.032\n",
      "Iter 181/200 - Loss: 2.650   lengthscale: 2.891   noise: 0.026\n",
      "(0.7932000160217285, 0.49166595935821533, 0.08232767879962921)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP vanilla\n",
    "y_MAGIC_train_induced_mu, y_MAGIC_train_induced_var = classification_models.transform_y_beta_LM(y_MAGIC_train_induced)\n",
    "LMGP_model_MAGIC, LMGP_likelihood_MAGIC = classification_models.create_LM_beta_GP_model(X_MAGIC_train_induced, y_MAGIC_train_induced_mu,\n",
    "                                                y_MAGIC_train_induced_var, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_MAGIC)\n",
    "LMGP_model_MAGIC, LMGP_likelihood_MAGIC = classification_models.train_LM_beta_GP_model(X_MAGIC_train_induced, y_MAGIC_train_induced_mu,\n",
    "                    LMGP_model_MAGIC, LMGP_likelihood_MAGIC, num_iter=NUM_ITER_MAGIC, lr=LR_MAGIC, report_iter=NUM_ITER_MAGIC//10)\n",
    "MAGIC_LMGP_res = classification_models.evaluate_LM_beta_GP(LMGP_model_MAGIC, LMGP_likelihood_MAGIC, X_MAGIC_test, y_MAGIC_test)\n",
    "print(MAGIC_LMGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.124   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 1.675   lengthscale: 3.445   noise: 0.139\n",
      "Iter 41/200 - Loss: 1.615   lengthscale: 3.478   noise: 0.048\n",
      "Iter 61/200 - Loss: 1.602   lengthscale: 3.340   noise: 0.028\n",
      "Iter 81/200 - Loss: 1.598   lengthscale: 3.473   noise: 0.020\n",
      "Iter 101/200 - Loss: 1.595   lengthscale: 3.522   noise: 0.016\n",
      "Iter 121/200 - Loss: 1.593   lengthscale: 3.563   noise: 0.013\n",
      "Iter 141/200 - Loss: 1.592   lengthscale: 3.608   noise: 0.011\n",
      "Iter 161/200 - Loss: 1.591   lengthscale: 3.643   noise: 0.009\n",
      "Iter 181/200 - Loss: 1.591   lengthscale: 3.675   noise: 0.008\n",
      "(0.8162000179290771, 0.40867048501968384, 0.04362637922167778)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP with conjugacy information\n",
    "\n",
    "train_mu_LB_con_MAGIC, train_var_LB_con_MAGIC = classification_models.LM_beta(y_MAGIC_train_induced_alphas, y_MAGIC_train_induced_betas)\n",
    "LMGP_model_con_MAGIC, LMGP_likelihood_con_MAGIC = classification_models.create_LM_beta_GP_model(X_MAGIC_train_induced, train_mu_LB_con_MAGIC,\n",
    "                                                train_var_LB_con_MAGIC, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_MAGIC)\n",
    "LMGP_model_con_MAGIC, LMGP_likelihood_con_MAGIC = classification_models.train_LM_beta_GP_model(X_MAGIC_train_induced, train_mu_LB_con_MAGIC,\n",
    "                LMGP_model_con_MAGIC, LMGP_likelihood_con_MAGIC, num_iter=NUM_ITER_MAGIC, lr=LR_MAGIC, report_iter=NUM_ITER_MAGIC//10)\n",
    "\n",
    "MAGIC_LMGP_con_res = classification_models.evaluate_LM_beta_GP(LMGP_model_con_MAGIC, LMGP_likelihood_con_MAGIC, X_MAGIC_test, y_MAGIC_test)\n",
    "print(MAGIC_LMGP_con_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiniBoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose lengthscale with CV\n",
    "NUM_ITER_MiniBoo = 200\n",
    "LR_MiniBoo = 0.1\n",
    "\"\"\"\n",
    "res_MiniBoo = classification_models.select_init_lengthscale_with_CV(X_MiniBoo_train, y_MiniBoo_train, mode=\"DGP\",\n",
    "                                    num_inducing_points=NUM_INDUCING_POINTS_MiniBoo, \n",
    "                                    learn_noise=True, num_iter=NUM_ITER_MiniBoo, lr=LR_MiniBoo,\n",
    "                                    lengthscales=LENGTHSCALES)\n",
    "print(res_MiniBoo)    \n",
    "classification_utils.plot_res(res_MiniBoo)\n",
    "\"\"\"\n",
    "\n",
    "INIT_LENGHTSCALE_MiniBoo = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 4.973   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 4.445   lengthscale: 2.704   noise: 1.299\n",
      "Iter 41/200 - Loss: 4.388   lengthscale: 2.939   noise: 0.970\n",
      "Iter 61/200 - Loss: 4.370   lengthscale: 2.887   noise: 0.978\n",
      "Iter 81/200 - Loss: 4.356   lengthscale: 2.688   noise: 0.887\n",
      "Iter 101/200 - Loss: 4.333   lengthscale: 2.338   noise: 0.727\n",
      "Iter 121/200 - Loss: 4.309   lengthscale: 1.943   noise: 0.611\n",
      "Iter 141/200 - Loss: 4.305   lengthscale: 1.931   noise: 0.595\n",
      "Iter 161/200 - Loss: 4.303   lengthscale: 1.973   noise: 0.591\n",
      "Iter 181/200 - Loss: 4.302   lengthscale: 1.964   noise: 0.590\n",
      "(0.866599977016449, 0.33838561177253723, 0.029760224744677544)\n"
     ]
    }
   ],
   "source": [
    "### run Dirichlet GPC\n",
    "\n",
    "DGP_model, DGP_likelihood = classification_models.create_DGP_model(X_MiniBoo_train_induced, y_MiniBoo_train_induced,\n",
    "                                        init_lengthscale=INIT_LENGHTSCALE_MiniBoo, learn_additional_noise=True)\n",
    "DGP_model, DGP_likelihood = classification_models.train_DGP_model(X_MiniBoo_train_induced,\n",
    "                                DGP_model, DGP_likelihood, num_iter=NUM_ITER_MiniBoo, lr=LR_MiniBoo, report_iter=NUM_ITER_MiniBoo//10)\n",
    "MiniBoo_DGP_res = classification_models.evaluate_DGP(DGP_model, DGP_likelihood, X_MiniBoo_test, y_MiniBoo_test)\n",
    "print(MiniBoo_DGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.755   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.610   lengthscale: 2.559   noise: 0.278\n",
      "Iter 41/200 - Loss: 2.579   lengthscale: 2.291   noise: 0.058\n",
      "Iter 61/200 - Loss: 2.571   lengthscale: 2.344   noise: 0.025\n",
      "Iter 81/200 - Loss: 2.567   lengthscale: 2.389   noise: 0.016\n",
      "Iter 101/200 - Loss: 2.564   lengthscale: 2.391   noise: 0.012\n",
      "Iter 121/200 - Loss: 2.563   lengthscale: 2.409   noise: 0.009\n",
      "Iter 141/200 - Loss: 2.562   lengthscale: 2.427   noise: 0.007\n",
      "Iter 161/200 - Loss: 2.561   lengthscale: 2.441   noise: 0.006\n",
      "Iter 181/200 - Loss: 2.561   lengthscale: 2.455   noise: 0.005\n",
      "(0.8677999973297119, 0.3311293423175812, 0.012597399763762951)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP vanilla\n",
    "y_MiniBoo_train_induced_mu, y_MiniBoo_train_induced_var = classification_models.transform_y_beta_LM(y_MiniBoo_train_induced)\n",
    "LMGP_model_MiniBoo, LMGP_likelihood_MiniBoo = classification_models.create_LM_beta_GP_model(X_MiniBoo_train_induced, y_MiniBoo_train_induced_mu,\n",
    "                                                y_MiniBoo_train_induced_var, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_MiniBoo)\n",
    "LMGP_model_MiniBoo, LMGP_likelihood_MiniBoo = classification_models.train_LM_beta_GP_model(X_MiniBoo_train_induced, y_MiniBoo_train_induced_mu,\n",
    "                    LMGP_model_MiniBoo, LMGP_likelihood_MiniBoo, num_iter=NUM_ITER_MiniBoo, lr=LR_MiniBoo, report_iter=NUM_ITER_MiniBoo//10)\n",
    "MiniBoo_LMGP_res = classification_models.evaluate_LM_beta_GP(LMGP_model_MiniBoo, LMGP_likelihood_MiniBoo, X_MiniBoo_test, y_MiniBoo_test)\n",
    "print(MiniBoo_LMGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.059   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 1.892   lengthscale: 2.156   noise: 0.162\n",
      "Iter 41/200 - Loss: 1.870   lengthscale: 2.274   noise: 0.093\n",
      "Iter 61/200 - Loss: 1.864   lengthscale: 2.337   noise: 0.092\n",
      "Iter 81/200 - Loss: 1.861   lengthscale: 2.394   noise: 0.098\n",
      "Iter 101/200 - Loss: 1.860   lengthscale: 2.441   noise: 0.100\n",
      "Iter 121/200 - Loss: 1.859   lengthscale: 2.470   noise: 0.099\n",
      "Iter 141/200 - Loss: 1.858   lengthscale: 2.496   noise: 0.098\n",
      "Iter 161/200 - Loss: 1.858   lengthscale: 2.518   noise: 0.097\n",
      "Iter 181/200 - Loss: 1.857   lengthscale: 2.536   noise: 0.097\n",
      "(0.8726000189781189, 0.2973827123641968, 0.02488512359559536)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP with conjugacy information\n",
    "\n",
    "train_mu_LB_con_MiniBoo, train_var_LB_con_MiniBoo = classification_models.LM_beta(y_MiniBoo_train_induced_alphas, y_MiniBoo_train_induced_betas)\n",
    "LMGP_model_con_MiniBoo, LMGP_likelihood_con_MiniBoo = classification_models.create_LM_beta_GP_model(X_MiniBoo_train_induced, train_mu_LB_con_MiniBoo,\n",
    "                                                train_var_LB_con_MiniBoo, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_MiniBoo)\n",
    "LMGP_model_con_MiniBoo, LMGP_likelihood_con_MiniBoo = classification_models.train_LM_beta_GP_model(X_MiniBoo_train_induced, train_mu_LB_con_MiniBoo,\n",
    "                LMGP_model_con_MiniBoo, LMGP_likelihood_con_MiniBoo, num_iter=NUM_ITER_MiniBoo, lr=LR_MiniBoo, report_iter=NUM_ITER_MiniBoo//10)\n",
    "\n",
    "MiniBoo_LMGP_con_res = classification_models.evaluate_LM_beta_GP(LMGP_model_con_MiniBoo, LMGP_likelihood_con_MiniBoo, X_MiniBoo_test, y_MiniBoo_test)\n",
    "print(MiniBoo_LMGP_con_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = {\n",
    "    \"EEG_res\":{\n",
    "        \"DGP\":list(EEG_DGP_res), \n",
    "        \"LMGP\":list(EEG_LMGP_res), \n",
    "        \"LMGP_con\":list(EEG_LMGP_con_res)\n",
    "    },\n",
    "    \"HTRU2_res\":{\n",
    "        \"DGP\":list(HTRU2_DGP_res), \n",
    "        \"LMGP\":list(HTRU2_LMGP_res), \n",
    "        \"LMGP_con\":list(HTRU2_LMGP_con_res)\n",
    "    },\n",
    "    \"MAGIC_res\":{\n",
    "        \"DGP\":list(MAGIC_DGP_res), \n",
    "        \"LMGP\":list(MAGIC_LMGP_res), \n",
    "        \"LMGP_con\":list(MAGIC_LMGP_con_res)\n",
    "    },\n",
    "    \"MiniBoo_res\":{\n",
    "        \"DGP\":list(MiniBoo_DGP_res), \n",
    "        \"LMGP\":list(MiniBoo_LMGP_res), \n",
    "        \"LMGP_con\":list(MiniBoo_LMGP_con_res)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EEG_res': {'DGP': [0.6467499732971191, 0.7012051939964294, 0.12777778506278992], 'LMGP': [0.606249988079071, 0.7131885290145874, 0.14380775392055511], 'LMGP_con': [0.7127500176429749, 0.5398080348968506, 0.021660421043634415]}, 'HTRU2_res': {'DGP': [0.9782000184059143, 0.07795679569244385, 0.03839163854718208], 'LMGP': [0.9768000245094299, 0.0793921947479248, 0.039690300822257996], 'LMGP_con': [0.9796000123023987, 0.07123546302318573, 0.04246756061911583]}, 'MAGIC_res': {'DGP': [0.795799970626831, 0.5362366437911987, 0.10130868852138519], 'LMGP': [0.7932000160217285, 0.49166595935821533, 0.08232767879962921], 'LMGP_con': [0.8162000179290771, 0.40867048501968384, 0.04362637922167778]}, 'MiniBoo_res': {'DGP': [0.866599977016449, 0.33838561177253723, 0.029760224744677544], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(all_res)\n",
    "#save results for this seed\n",
    "\n",
    "res_file = open(\"results/bin_class_seed_{}.json\".format(seed), \"w\")\n",
    "json.dump(all_res, res_file)\n",
    "res_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-36-6aaf1f276005>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-6aaf1f276005>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EEG_res': {'DGP': [0.5885000228881836, 0.7486024498939514, 0.17264671623706818], 'LMGP': [0.5569999814033508, 0.729259729385376, 0.09519588202238083], 'LMGP_con': [0.6862499713897705, 0.5671086311340332, 0.013570543378591537]}, 'HTRU2_res': {'DGP': [0.9779999852180481, 0.07645564526319504, 0.039890140295028687], 'LMGP': [0.977400004863739, 0.07888096570968628, 0.039150871336460114], 'LMGP_con': [0.9797999858856201, 0.07336153835058212, 0.04176821559667587]}, 'MAGIC_res': {'DGP': [0.7919999957084656, 0.6402088403701782, 0.1169930025935173], 'LMGP': [0.7914000153541565, 0.552958607673645, 0.09899098426103592], 'LMGP_con': [0.824999988079071, 0.4007170796394348, 0.05011987313628197]}, 'MiniBoo_res': {'DGP': [0.8668000102043152, 0.33881834149360657, 0.029520491138100624], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n",
      "{'EEG_res': {'DGP': [0.6362500190734863, 0.6315459609031677, 0.0551435723900795], 'LMGP': [0.578000009059906, 0.6621639132499695, 0.07444444298744202], 'LMGP_con': [0.6955000162124634, 0.5480953454971313, 0.021535592153668404]}, 'HTRU2_res': {'DGP': [0.9733999967575073, 0.09256896376609802, 0.038171835243701935], 'LMGP': [0.9721999764442444, 0.08989989757537842, 0.03927072510123253], 'LMGP_con': [0.9751999974250793, 0.0848274752497673, 0.037392597645521164]}, 'MAGIC_res': {'DGP': [0.8011999726295471, 0.5869053602218628, 0.09643355011940002], 'LMGP': [0.7937999963760376, 0.5216696262359619, 0.08734266459941864], 'LMGP_con': [0.8212000131607056, 0.4114838242530823, 0.04946053400635719]}, 'MiniBoo_res': {'DGP': [0.8664000034332275, 0.3383502960205078, 0.029980000108480453], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n",
      "{'EEG_res': {'DGP': [0.5872499942779541, 0.7239165902137756, 0.13644194602966309], 'LMGP': [0.5852500200271606, 0.6865164041519165, 0.10098625719547272], 'LMGP_con': [0.6875, 0.5505354404449463, 0.019013741984963417]}, 'HTRU2_res': {'DGP': [0.9739999771118164, 0.09063036739826202, 0.03817182406783104], 'LMGP': [0.9715999960899353, 0.09093181788921356, 0.037572432309389114], 'LMGP_con': [0.975600004196167, 0.07962378114461899, 0.03939061611890793]}, 'MAGIC_res': {'DGP': [0.7968000173568726, 0.553565263748169, 0.10956043750047684], 'LMGP': [0.7990000247955322, 0.4814997911453247, 0.07971030473709106], 'LMGP_con': [0.8235999941825867, 0.40687790513038635, 0.047222789376974106]}, 'MiniBoo_res': {'DGP': [0.8669999837875366, 0.338272362947464, 0.02952045202255249], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n",
      "{'EEG_res': {'DGP': [0.6807500123977661, 0.6890937685966492, 0.10687888413667679], 'LMGP': [0.671999990940094, 0.6624484658241272, 0.07404493540525436], 'LMGP_con': [0.6875, 0.548423171043396, 0.02717852033674717]}, 'HTRU2_res': {'DGP': [0.9764000177383423, 0.08670683950185776, 0.0359540618956089], 'LMGP': [0.973800003528595, 0.08550375699996948, 0.04116884991526604], 'LMGP_con': [0.9783999919891357, 0.07691948115825653, 0.0431668646633625]}, 'MAGIC_res': {'DGP': [0.800599992275238, 0.5621601343154907, 0.10818183422088623], 'LMGP': [0.7993999719619751, 0.4891148507595062, 0.0902397632598877], 'LMGP_con': [0.8334000110626221, 0.38137179613113403, 0.06030968576669693]}, 'MiniBoo_res': {'DGP': [0.8669999837875366, 0.3374374210834503, 0.02936064451932907], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n",
      "{'EEG_res': {'DGP': [0.6467499732971191, 0.7012051939964294, 0.12777778506278992], 'LMGP': [0.606249988079071, 0.7131885290145874, 0.14380775392055511], 'LMGP_con': [0.7127500176429749, 0.5398080348968506, 0.021660421043634415]}, 'HTRU2_res': {'DGP': [0.9782000184059143, 0.07795679569244385, 0.03839163854718208], 'LMGP': [0.9768000245094299, 0.0793921947479248, 0.039690300822257996], 'LMGP_con': [0.9796000123023987, 0.07123546302318573, 0.04246756061911583]}, 'MAGIC_res': {'DGP': [0.795799970626831, 0.5362366437911987, 0.10130868852138519], 'LMGP': [0.7932000160217285, 0.49166595935821533, 0.08232767879962921], 'LMGP_con': [0.8162000179290771, 0.40867048501968384, 0.04362637922167778]}, 'MiniBoo_res': {'DGP': [0.866599977016449, 0.33838561177253723, 0.029760224744677544], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n"
     ]
    }
   ],
   "source": [
    "### over all seeds\n",
    "\n",
    "DGP_acc_all = []\n",
    "LMGP_acc_all = []\n",
    "LMGP_con_acc_all = []\n",
    "DGP_mnll_all = []\n",
    "LMGP_mnll_all = []\n",
    "LMGP_con_mnll_all = []\n",
    "DGP_ece_all = []\n",
    "LMGP_ece_all = []\n",
    "LMGP_con_ece_all = []\n",
    "\n",
    "for seed in range(5):\n",
    "    seed +=1\n",
    "\n",
    "    with open('results/bin_class_seed_{}.json'.format(seed)) as json_file:\n",
    "        all_res = json.load(json_file)\n",
    "    print(all_res)\n",
    "\n",
    "    DGP_acc = []\n",
    "    LMGP_acc = []\n",
    "    LMGP_con_acc = []\n",
    "    DGP_mnll = []\n",
    "    LMGP_mnll = []\n",
    "    LMGP_con_mnll = []\n",
    "    DGP_ece = []\n",
    "    LMGP_ece = []\n",
    "    LMGP_con_ece = []\n",
    "\n",
    "    for dataset in [\"EEG_res\", \"HTRU2_res\", \"MAGIC_res\", \"MiniBoo_res\"]:\n",
    "\n",
    "        DGP_acc.append(all_res[dataset][\"DGP\"][0])\n",
    "        LMGP_acc.append(all_res[dataset][\"LMGP\"][0])\n",
    "        LMGP_con_acc.append(all_res[dataset][\"LMGP_con\"][0])\n",
    "        DGP_mnll.append(all_res[dataset][\"DGP\"][1])\n",
    "        LMGP_mnll.append(all_res[dataset][\"LMGP\"][1])\n",
    "        LMGP_con_mnll.append(all_res[dataset][\"LMGP_con\"][1])\n",
    "        DGP_ece.append(all_res[dataset][\"DGP\"][2])\n",
    "        LMGP_ece.append(all_res[dataset][\"LMGP\"][2])\n",
    "        LMGP_con_ece.append(all_res[dataset][\"LMGP_con\"][2])\n",
    "        \n",
    "    DGP_acc_all.append(DGP_acc)\n",
    "    LMGP_acc_all.append(LMGP_acc)\n",
    "    LMGP_con_acc_all.append(LMGP_con_acc)\n",
    "    DGP_mnll_all.append(DGP_mnll)\n",
    "    LMGP_mnll_all.append(LMGP_mnll)\n",
    "    LMGP_con_mnll_all.append(LMGP_con_mnll)\n",
    "    DGP_ece_all.append(DGP_ece)\n",
    "    LMGP_ece_all.append(LMGP_ece)\n",
    "    LMGP_con_ece_all.append(LMGP_con_ece)\n",
    "    \n",
    "DGP_acc_mean = np.array(DGP_acc_all).mean(0)\n",
    "LMGP_acc_mean = np.array(LMGP_acc_all).mean(0)\n",
    "LMGP_con_acc_mean = np.array(LMGP_con_acc_all).mean(0)\n",
    "DGP_mnll_mean = np.array(DGP_mnll_all).mean(0)\n",
    "LMGP_mnll_mean = np.array(LMGP_mnll_all).mean(0)\n",
    "LMGP_con_mnll_mean = np.array(LMGP_con_mnll_all).mean(0)\n",
    "DGP_ece_mean = np.array(DGP_ece_all).mean(0)\n",
    "LMGP_ece_mean = np.array(LMGP_ece_all).mean(0)\n",
    "LMGP_con_ece_mean = np.array(LMGP_con_ece_all).mean(0)\n",
    "\n",
    "DGP_acc_std = np.array(DGP_acc_all).std(0)\n",
    "LMGP_acc_std = np.array(LMGP_acc_all).std(0)\n",
    "LMGP_con_acc_std = np.array(LMGP_con_acc_all).std(0)\n",
    "DGP_mnll_std = np.array(DGP_mnll_all).std(0)\n",
    "LMGP_mnll_std = np.array(LMGP_mnll_all).std(0)\n",
    "LMGP_con_mnll_std = np.array(LMGP_con_mnll_all).std(0)\n",
    "DGP_ece_std = np.array(DGP_ece_all).std(0)\n",
    "LMGP_ece_std = np.array(LMGP_ece_all).std(0)\n",
    "LMGP_con_ece_std = np.array(LMGP_con_ece_all).std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x1000 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "w=0.23\n",
    "c=0.25\n",
    "x=np.arange(4)\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(8, 5), dpi=200, sharex=True)\n",
    "\n",
    "ax[0].bar(x-1*c, DGP_acc_mean, width=w, yerr=2*DGP_acc_std, color=\"firebrick\", label=\"DGP\")\n",
    "ax[0].bar(x, LMGP_acc_mean, width=w, yerr=2*LMGP_acc_std, color=\"cornflowerblue\", label=\"LM(Beta)+GP\")\n",
    "ax[0].bar(x+1*c, LMGP_con_acc_mean, width=w, yerr=2*LMGP_con_acc_std, color=\"orange\", label=\"LM(Beta)+GP+conjugacy\")\n",
    "ax[0].grid()\n",
    "ax[0].set_ylim(0, 1.05)\n",
    "ax[0].set_ylabel(u\"Accuracy \\u2192\")\n",
    "#ax[0].legend()\n",
    "\n",
    "ax[1].bar(x-1*c, DGP_mnll_mean, width=w, yerr=2*DGP_mnll_std, color=\"firebrick\", label=\"DGP\")\n",
    "ax[1].bar(x, LMGP_mnll_mean, width=w, yerr=2*LMGP_mnll_std, color=\"cornflowerblue\", label=\"LM(Beta)+GP\")\n",
    "ax[1].bar(x+1*c, LMGP_con_mnll_mean, width=w, yerr=2*LMGP_con_mnll_std, color=\"orange\", label=\"LM(Beta)+GP+conjugacy\")\n",
    "ax[1].grid()\n",
    "ax[1].set_ylabel(u\"MNLL \\u2190\")\n",
    "\n",
    "ax[2].bar(x-1*c, DGP_ece_mean, width=w, yerr=2*DGP_ece_std, color=\"firebrick\", label=\"DGP\")\n",
    "ax[2].bar(x, LMGP_ece_mean, width=w, yerr=2*LMGP_ece_std, color=\"cornflowerblue\", label=\"LM(Beta)+GP\")\n",
    "ax[2].bar(x+1*c, LMGP_con_ece_mean, width=w, yerr=2*LMGP_con_ece_std, color=\"orange\", label=\"LM(Beta)+GP+conjugacy\")\n",
    "ax[2].grid()\n",
    "ax[2].set_ylabel(u\"ECE \\u2190\")\n",
    "ax[2].legend()\n",
    "\n",
    "ax[2].set_xticks(x)\n",
    "ax[2].set_xticklabels([\"EEG\", \"HTRU2\", \"MAGIC\", \"MiniBoo\"])\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
