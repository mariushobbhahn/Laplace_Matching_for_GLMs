{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "\n",
    "- TODO: description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.699593426303529 5.499999861629998\n"
     ]
    }
   ],
   "source": [
    "from tueplots import bundles\n",
    "plt.rcParams.update(bundles.neurips2021())\n",
    "figheight = bundles.neurips2021()[\"figure.figsize\"][1]\n",
    "figwidth = bundles.neurips2021()[\"figure.figsize\"][0]\n",
    "print(figheight, figwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "py_file_location = '../utils'\n",
    "sys.path.append(os.path.abspath(py_file_location))\n",
    "py_file_location = '../models'\n",
    "sys.path.append(os.path.abspath(py_file_location))\n",
    "\n",
    "import classification_utils\n",
    "import classification_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5 #1,2,3,4,5\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all datasets\n",
    "\n",
    "The four datasets we use are \n",
    "- EEG\n",
    "- HTRU2\n",
    "- MAGIC\n",
    "- MiniBoo\n",
    "All of them are UCI datasets that were already used for the Dirichlet GPC paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329.23</td>\n",
       "      <td>4009.23</td>\n",
       "      <td>4289.23</td>\n",
       "      <td>4148.21</td>\n",
       "      <td>4350.26</td>\n",
       "      <td>4586.15</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4641.03</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4238.46</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4635.90</td>\n",
       "      <td>4393.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4328.72</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4296.41</td>\n",
       "      <td>4155.90</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4630.77</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4235.38</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4632.31</td>\n",
       "      <td>4396.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4292.31</td>\n",
       "      <td>4151.28</td>\n",
       "      <td>4347.69</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4095.90</td>\n",
       "      <td>4627.69</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4244.10</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4398.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1        2        3        4        5        6        7   \\\n",
       "0  4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
       "1  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
       "2  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
       "3  4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
       "4  4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
       "\n",
       "        8        9        10       11       12       13  14  \n",
       "0  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85   0  \n",
       "1  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10   0  \n",
       "2  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23   0  \n",
       "3  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41   0  \n",
       "4  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load EEG dataset\n",
    "data_files = \"data/\"\n",
    "\n",
    "EEG_filename = \"EEG_Eye_State.csv\"\n",
    "EEG_df = pd.read_csv(data_files + EEG_filename, header=None)\n",
    "EEG_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1         2         3         4          5          6  \\\n",
       "0  140.562500  55.683782 -0.234571 -0.699648  3.199833  19.110426   7.975532   \n",
       "1  102.507812  58.882430  0.465318 -0.515088  1.677258  14.860146  10.576487   \n",
       "2  103.015625  39.341649  0.323328  1.051164  3.121237  21.744669   7.735822   \n",
       "3  136.750000  57.178449 -0.068415 -0.636238  3.642977  20.959280   6.896499   \n",
       "4   88.726562  40.672225  0.600866  1.123492  1.178930  11.468720  14.269573   \n",
       "\n",
       "            7  8  \n",
       "0   74.242225  0  \n",
       "1  127.393580  0  \n",
       "2   63.171909  0  \n",
       "3   53.593661  0  \n",
       "4  252.567306  0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load HTRU2 dataset\n",
    "HTRU2_filename = \"HTRU_2.csv\"\n",
    "HTRU2_df = pd.read_csv(data_files + HTRU2_filename, header=None)\n",
    "HTRU2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1       2       3       4         5        6        7   \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
       "\n",
       "        8         9   10  \n",
       "0  40.0920   81.8828   1  \n",
       "1   6.3609  205.2610   1  \n",
       "2  76.9600  256.7880   1  \n",
       "3  10.4490  116.7370   1  \n",
       "4   4.6480  356.4620   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load MAGIC dataset\n",
    "MAGIC_filename = \"magic04.csv\"\n",
    "MAGIC_df = pd.read_csv(data_files + MAGIC_filename, header=None)\n",
    "\n",
    "#map final column from g/h to 1/0\n",
    "MAGIC_df = MAGIC_df.replace({\"g\":1, \"h\":0})\n",
    "\n",
    "MAGIC_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.96113</td>\n",
       "      <td>0.384599</td>\n",
       "      <td>1087.1200</td>\n",
       "      <td>0.251748</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.116820</td>\n",
       "      <td>0.872463</td>\n",
       "      <td>3.11779</td>\n",
       "      <td>0.185689</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.7970</td>\n",
       "      <td>0.947933</td>\n",
       "      <td>2.29170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242451</td>\n",
       "      <td>0.184653</td>\n",
       "      <td>2.975180</td>\n",
       "      <td>0.016929</td>\n",
       "      <td>0.236594</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.84353</td>\n",
       "      <td>1.741840</td>\n",
       "      <td>101.6440</td>\n",
       "      <td>0.295625</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.130203</td>\n",
       "      <td>1.171860</td>\n",
       "      <td>0.885831</td>\n",
       "      <td>3.40604</td>\n",
       "      <td>0.207060</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.3280</td>\n",
       "      <td>3.938770</td>\n",
       "      <td>6.63478</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.160161</td>\n",
       "      <td>0.220539</td>\n",
       "      <td>0.792976</td>\n",
       "      <td>0.056713</td>\n",
       "      <td>0.198655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.88238</td>\n",
       "      <td>2.748180</td>\n",
       "      <td>88.5783</td>\n",
       "      <td>0.300086</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737055</td>\n",
       "      <td>0.677884</td>\n",
       "      <td>3.89686</td>\n",
       "      <td>0.093560</td>\n",
       "      <td>...</td>\n",
       "      <td>-88.3881</td>\n",
       "      <td>-0.793292</td>\n",
       "      <td>3.08822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124882</td>\n",
       "      <td>0.367171</td>\n",
       "      <td>6.016120</td>\n",
       "      <td>6.133560</td>\n",
       "      <td>0.255304</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.43173</td>\n",
       "      <td>1.948110</td>\n",
       "      <td>103.1530</td>\n",
       "      <td>0.264039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191277</td>\n",
       "      <td>1.177080</td>\n",
       "      <td>0.883820</td>\n",
       "      <td>3.27063</td>\n",
       "      <td>0.169655</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.1426</td>\n",
       "      <td>0.435008</td>\n",
       "      <td>4.61928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127263</td>\n",
       "      <td>0.172886</td>\n",
       "      <td>0.985063</td>\n",
       "      <td>0.212094</td>\n",
       "      <td>0.203885</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.75619</td>\n",
       "      <td>0.405642</td>\n",
       "      <td>63.6347</td>\n",
       "      <td>0.233746</td>\n",
       "      <td>0.011423</td>\n",
       "      <td>0.406455</td>\n",
       "      <td>1.089350</td>\n",
       "      <td>0.883967</td>\n",
       "      <td>3.29230</td>\n",
       "      <td>0.207975</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.1712</td>\n",
       "      <td>0.097014</td>\n",
       "      <td>4.57457</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.129168</td>\n",
       "      <td>-0.085241</td>\n",
       "      <td>0.886991</td>\n",
       "      <td>-0.020713</td>\n",
       "      <td>0.273904</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1          2         3         4         5         6   \\\n",
       "0  3.96113  0.384599  1087.1200  0.251748  0.015258  0.000000  1.116820   \n",
       "1  3.84353  1.741840   101.6440  0.295625  0.002525  0.130203  1.171860   \n",
       "2  6.88238  2.748180    88.5783  0.300086  0.002597  0.000000  0.737055   \n",
       "3  3.43173  1.948110   103.1530  0.264039  0.000000  0.191277  1.177080   \n",
       "4  2.75619  0.405642    63.6347  0.233746  0.011423  0.406455  1.089350   \n",
       "\n",
       "         7        8         9   ...       41        42       43        44  \\\n",
       "0  0.872463  3.11779  0.185689  ... -19.7970  0.947933  2.29170  0.000000   \n",
       "1  0.885831  3.40604  0.207060  ... -32.3280  3.938770  6.63478  0.002525   \n",
       "2  0.677884  3.89686  0.093560  ... -88.3881 -0.793292  3.08822  0.000000   \n",
       "3  0.883820  3.27063  0.169655  ... -24.1426  0.435008  4.61928  0.000000   \n",
       "4  0.883967  3.29230  0.207975  ... -21.1712  0.097014  4.57457  0.001038   \n",
       "\n",
       "         45        46        47        48        49   50  \n",
       "0  0.242451  0.184653  2.975180  0.016929  0.236594  0.0  \n",
       "1  0.160161  0.220539  0.792976  0.056713  0.198655  1.0  \n",
       "2  0.124882  0.367171  6.016120  6.133560  0.255304  1.0  \n",
       "3  0.127263  0.172886  0.985063  0.212094  0.203885  1.0  \n",
       "4  0.129168 -0.085241  0.886991 -0.020713  0.273904  0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load Miniboo dataset\n",
    "train_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "# IMPORTANT: there are 10 splits for train and test. Each of them has 120K training points ... \n",
    "# However, the k-means clustering algorithm may take a while if we load all of them\n",
    "# Therefore, it might make more sense to just choose 1 split for the beginning.\n",
    "for i in range(1): #10\n",
    "    i_ = i+1\n",
    "    # load training\n",
    "    MiniBoo_filename_train = \"MiniBoo_splits/train{:02d}.txt\".format(i_)\n",
    "    MiniBoo_df_train = pd.read_csv(data_files + MiniBoo_filename_train, header=None)\n",
    "    train_dfs.append(MiniBoo_df_train)\n",
    "    # load test\n",
    "    MiniBoo_filename_test = \"MiniBoo_splits/test{:02d}.txt\".format(i_)\n",
    "    MiniBoo_df_test = pd.read_csv(data_files + MiniBoo_filename_test, header=None)\n",
    "    test_dfs.append(MiniBoo_df_test)\n",
    "    \n",
    "MiniBoo_train_df = pd.concat(train_dfs)\n",
    "MiniBoo_test_df = pd.concat(test_dfs)\n",
    "MiniBoo_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize & Create test train splits\n",
    "\n",
    "As in the Dirichlet GPC paper, we use the following test-train splits\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10980, 14)\n",
      "(4000, 14)\n",
      "(10980,)\n",
      "(4000,)\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# make test-train split for EEG\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_EEG = EEG_df.values[:,:-1]\n",
    "Y_EEG = EEG_df.values[:,-1]\n",
    "NUM_TRAINING_POINTS_EEG=10980\n",
    "NUM_TEST_POINTS_EEG=4000\n",
    "\n",
    "# Normalize data\n",
    "X_EEG = classification_utils.standardise(X_EEG)\n",
    "#X_EEG = classification_utils.normalise_minusonetoone(X_EEG)\n",
    "\n",
    "# The original paper chose 10980 training points and 4000 test points\n",
    "test_size_EEG = NUM_TEST_POINTS_EEG/(NUM_TRAINING_POINTS_EEG+NUM_TEST_POINTS_EEG)\n",
    "X_EEG_train, X_EEG_test, y_EEG_train, y_EEG_test = train_test_split(X_EEG, Y_EEG, test_size=test_size_EEG, random_state=seed)\n",
    "print(np.shape(X_EEG_train))\n",
    "print(np.shape(X_EEG_test))\n",
    "print(np.shape(y_EEG_train))\n",
    "print(np.shape(y_EEG_test))\n",
    "X_EEG_train, X_EEG_test, y_EEG_train, y_EEG_test = torch.tensor(X_EEG_train).float(), torch.tensor(X_EEG_test).float(), \\\n",
    "                                                   torch.tensor(y_EEG_train).long(), torch.tensor(y_EEG_test).long()\n",
    "print(y_EEG_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12898, 8)\n",
      "(5000, 8)\n",
      "(12898,)\n",
      "(5000,)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# make test-train split for HTRU2\n",
    "\n",
    "X_HTRU2 = HTRU2_df.values[:,:-1]\n",
    "Y_HTRU2 = HTRU2_df.values[:,-1]\n",
    "NUM_TRAINING_POINTS_HTRU2=12898\n",
    "NUM_TEST_POINTS_HTRU2=5000\n",
    "\n",
    "# Normalize data\n",
    "X_HTRU2 = classification_utils.standardise(X_HTRU2)\n",
    "#X_HTRU2 = classification_utils.normalise_minusonetoone(X_HTRU2)\n",
    "\n",
    "test_size_HTRU2 = NUM_TEST_POINTS_HTRU2/(NUM_TRAINING_POINTS_HTRU2+NUM_TEST_POINTS_HTRU2)\n",
    "X_HTRU2_train, X_HTRU2_test, y_HTRU2_train, y_HTRU2_test = train_test_split(X_HTRU2, Y_HTRU2, test_size=test_size_HTRU2, random_state=seed)\n",
    "print(np.shape(X_HTRU2_train))\n",
    "print(np.shape(X_HTRU2_test))\n",
    "print(np.shape(y_HTRU2_train))\n",
    "print(np.shape(y_HTRU2_test))\n",
    "X_HTRU2_train, X_HTRU2_test, y_HTRU2_train, y_HTRU2_test = torch.tensor(X_HTRU2_train).float(), torch.tensor(X_HTRU2_test).float(), \\\n",
    "                                                   torch.tensor(y_HTRU2_train).long(), torch.tensor(y_HTRU2_test).long()\n",
    "print(y_HTRU2_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14020, 10)\n",
      "(5000, 10)\n",
      "(14020,)\n",
      "(5000,)\n",
      "tensor([1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# make test-train split for MAGIC\n",
    "\n",
    "X_MAGIC = MAGIC_df.values[:,:-1]\n",
    "Y_MAGIC = MAGIC_df.values[:,-1]\n",
    "NUM_TRAINING_POINTS_MAGIC=14020\n",
    "NUM_TEST_POINTS_MAGIC=5000\n",
    "\n",
    "# Normalize data\n",
    "X_MAGIC = classification_utils.standardise(X_MAGIC)\n",
    "#X_MAGIC = classification_utils.normalise_minusonetoone(X_MAGIC)\n",
    "\n",
    "test_size_MAGIC = NUM_TEST_POINTS_MAGIC/(NUM_TRAINING_POINTS_MAGIC+NUM_TEST_POINTS_MAGIC)\n",
    "X_MAGIC_train, X_MAGIC_test, y_MAGIC_train, y_MAGIC_test = train_test_split(X_MAGIC, Y_MAGIC, test_size=test_size_MAGIC, random_state=seed)\n",
    "print(np.shape(X_MAGIC_train))\n",
    "print(np.shape(X_MAGIC_test))\n",
    "print(np.shape(y_MAGIC_train))\n",
    "print(np.shape(y_MAGIC_test))\n",
    "X_MAGIC_train, X_MAGIC_test, y_MAGIC_train, y_MAGIC_test = torch.tensor(X_MAGIC_train).float(), torch.tensor(X_MAGIC_test).float(), \\\n",
    "                                                   torch.tensor(y_MAGIC_train).long(), torch.tensor(y_MAGIC_test).long()\n",
    "print(y_MAGIC_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 50)\n",
      "(5000, 50)\n",
      "(20000,)\n",
      "(5000,)\n",
      "tensor([1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# make test-train split for MiniBoo\n",
    "\n",
    "X_MiniBoo_train = MiniBoo_train_df.values[:,:-1]\n",
    "y_MiniBoo_train = MiniBoo_train_df.values[:,-1]\n",
    "X_MiniBoo_test = MiniBoo_test_df.values[:,:-1]\n",
    "y_MiniBoo_test = MiniBoo_test_df.values[:,-1]\n",
    "\n",
    "# IMPORTANT: the miniboo dataset is kinda large (120K datapoints)\n",
    "# Therefore, we'll prune it when testing the code.\n",
    "X_MiniBoo_train = X_MiniBoo_train[:20000,:]\n",
    "y_MiniBoo_train = y_MiniBoo_train[:20000]\n",
    "X_MiniBoo_test = X_MiniBoo_test[:5000,:]\n",
    "y_MiniBoo_test = y_MiniBoo_test[:5000]\n",
    "\n",
    "# Normalize data\n",
    "X_MiniBoo_train = classification_utils.standardise(X_MiniBoo_train)\n",
    "X_MiniBoo_test = classification_utils.standardise(X_MiniBoo_test)\n",
    "#X_MiniBoo = classification_utils.normalise_minusonetoone(X_MiniBoo)\n",
    "\n",
    "print(np.shape(X_MiniBoo_train))\n",
    "print(np.shape(X_MiniBoo_test))\n",
    "print(np.shape(y_MiniBoo_train))\n",
    "print(np.shape(y_MiniBoo_test))\n",
    "X_MiniBoo_train, X_MiniBoo_test, y_MiniBoo_train, y_MiniBoo_test = torch.tensor(X_MiniBoo_train).float(), torch.tensor(X_MiniBoo_test).float(), \\\n",
    "                                                   torch.tensor(y_MiniBoo_train).long(), torch.tensor(y_MiniBoo_test).long()\n",
    "print(y_MiniBoo_test[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create inducing points\n",
    "\n",
    "As in the Dirichlet GPC paper, we use the following number of inducing points\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INDUCING_POINTS_EEG=200\n",
    "NUM_INDUCING_POINTS_HTRU2=200\n",
    "NUM_INDUCING_POINTS_MAGIC=200\n",
    "NUM_INDUCING_POINTS_MiniBoo=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.0884e-02,  2.3213e+00,  8.2130e-01,  4.0649e-03,  6.7907e-02,\n",
      "         -9.0890e-03, -8.8377e-03, -1.0732e+00, -2.1053e-02, -2.1646e-01,\n",
      "          5.3204e-01,  9.0719e-01,  2.0520e-02,  1.2531e-02],\n",
      "        [-3.4462e-03, -8.7130e-01, -9.7336e-03, -1.3925e-02, -2.8646e-01,\n",
      "         -1.5404e-02, -3.4864e-03,  2.9466e-02, -4.4921e-03,  3.8985e-01,\n",
      "          1.1159e+00,  5.6152e-01,  4.4710e-02,  2.5703e-04]]) tensor([0, 1])\n",
      "tensor([[ 5.0884e-02,  2.3213e+00,  8.2130e-01,  4.0649e-03,  6.7907e-02,\n",
      "         -9.0890e-03, -8.8377e-03, -1.0732e+00, -2.1053e-02, -2.1646e-01,\n",
      "          5.3204e-01,  9.0719e-01,  2.0520e-02,  1.2531e-02],\n",
      "        [-3.4462e-03, -8.7130e-01, -9.7336e-03, -1.3925e-02, -2.8646e-01,\n",
      "         -1.5404e-02, -3.4864e-03,  2.9466e-02, -4.4921e-03,  3.8985e-01,\n",
      "          1.1159e+00,  5.6152e-01,  4.4710e-02,  2.5703e-04]]) tensor([12.0100, 36.0100]) tensor([18.0100,  2.0100])\n"
     ]
    }
   ],
   "source": [
    "### EEG\n",
    "\n",
    "## choose random inducing points\n",
    "#X_EEG_train_induced, y_EEG_train_induced = classification_utils.random_inducing_points(X_EEG_train, y_EEG_train, NUM_INDUCING_POINTS_EEG)\n",
    "\n",
    "## use kmeans for inducing points\n",
    "X_EEG_train_induced, y_EEG_train_induced = classification_utils.k_means_inducing_points(X_EEG_train, y_EEG_train, NUM_INDUCING_POINTS_EEG)\n",
    "print(X_EEG_train_induced[:2], y_EEG_train_induced[:2])\n",
    "\n",
    "# use the conjugacy of the Beta to create better inducing points\n",
    "X_EEG_train_induced, y_EEG_train_induced_alphas, y_EEG_train_induced_betas = classification_utils.k_means_inducing_points_LM_beta(X_EEG_train, y_EEG_train, NUM_INDUCING_POINTS_EEG)\n",
    "print(X_EEG_train_induced[:2], y_EEG_train_induced_alphas[:2], y_EEG_train_induced_betas[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3313,  1.4238, -0.2694, -0.3310, -0.3440, -0.4739,  0.2409, -0.0279],\n",
      "        [-2.1703, -0.7639,  2.2148,  1.1235,  3.4244,  2.6550, -1.8571, -0.9940]]) tensor([0, 1])\n",
      "tensor([[ 0.3313,  1.4238, -0.2694, -0.3310, -0.3440, -0.4739,  0.2409, -0.0279],\n",
      "        [-2.1703, -0.7639,  2.2148,  1.1235,  3.4244,  2.6550, -1.8571, -0.9940]]) tensor([ 2.0100, 16.0100]) tensor([126.0100,   2.0100])\n"
     ]
    }
   ],
   "source": [
    "### HTRU2\n",
    "\n",
    "## choose random inducing points\n",
    "#X_HTRU2_train_induced, y_HTRU2_train_induced = classification_utils.random_inducing_points(X_HTRU2_train, y_HTRU2_train, NUM_INDUCING_POINTS_HTRU2)\n",
    "\n",
    "## use kmeans for inducing points\n",
    "X_HTRU2_train_induced, y_HTRU2_train_induced = classification_utils.k_means_inducing_points(X_HTRU2_train, y_HTRU2_train, NUM_INDUCING_POINTS_HTRU2)\n",
    "print(X_HTRU2_train_induced[:2], y_HTRU2_train_induced[:2])\n",
    "\n",
    "# use the conjugacy of the Beta to create better inducing points\n",
    "X_HTRU2_train_induced, y_HTRU2_train_induced_alphas, y_HTRU2_train_induced_betas = classification_utils.k_means_inducing_points_LM_beta(X_HTRU2_train, y_HTRU2_train, NUM_INDUCING_POINTS_HTRU2)\n",
    "print(X_HTRU2_train_induced[:2], y_HTRU2_train_induced_alphas[:2], y_HTRU2_train_induced_betas[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7744, -0.8129, -1.6624,  1.8160,  1.4872,  0.0502, -0.0455, -0.2872,\n",
      "         -0.6087, -0.8407],\n",
      "        [-0.2652, -0.3498,  0.1991, -0.5122, -0.6394,  0.3475,  0.3502, -0.5967,\n",
      "         -1.0236,  0.0660]]) tensor([1, 1])\n",
      "tensor([[-0.7744, -0.8129, -1.6624,  1.8160,  1.4872,  0.0502, -0.0455, -0.2872,\n",
      "         -0.6087, -0.8407],\n",
      "        [-0.2652, -0.3498,  0.1991, -0.5122, -0.6394,  0.3475,  0.3502, -0.5967,\n",
      "         -1.0236,  0.0660]]) tensor([116.0100, 190.0100]) tensor([23.0100,  9.0100])\n"
     ]
    }
   ],
   "source": [
    "### MAGIC\n",
    "\n",
    "## choose random inducing points\n",
    "#X_MAGIC_train_induced, y_MAGIC_train_induced = classification_utils.random_inducing_points(X_MAGIC_train, y_MAGIC_train, NUM_INDUCING_POINTS_MAGIC)\n",
    "\n",
    "## use kmeans for inducing points\n",
    "X_MAGIC_train_induced, y_MAGIC_train_induced = classification_utils.k_means_inducing_points(X_MAGIC_train, y_MAGIC_train, NUM_INDUCING_POINTS_MAGIC)\n",
    "print(X_MAGIC_train_induced[:2], y_MAGIC_train_induced[:2])\n",
    "\n",
    "# use the conjugacy of the Beta to create better inducing points\n",
    "X_MAGIC_train_induced, y_MAGIC_train_induced_alphas, y_MAGIC_train_induced_betas = classification_utils.k_means_inducing_points_LM_beta(X_MAGIC_train, y_MAGIC_train, NUM_INDUCING_POINTS_MAGIC)\n",
    "print(X_MAGIC_train_induced[:2], y_MAGIC_train_induced_alphas[:2], y_MAGIC_train_induced_betas[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.3033e-02,  5.3380e-02, -1.3805e-02,  6.1487e-02,  6.2018e-02,\n",
      "          6.1813e-02,  6.2235e-02,  6.3347e-02,  5.6586e-02,  6.1945e-02,\n",
      "          5.7336e-02, -9.7243e-01,  6.7089e-02,  5.7450e-02,  7.2649e-02,\n",
      "          2.0188e-01,  6.3359e-02, -5.2585e-02,  6.1781e-02,  3.9299e-02,\n",
      "          7.9400e-02,  6.3935e-02,  5.9228e-01,  5.0811e-02,  6.2558e-02,\n",
      "          8.1421e-02,  7.4281e-01,  6.1410e-02,  6.1776e-02,  6.3557e-02,\n",
      "          3.8173e-02,  6.5781e-02,  5.8706e-02,  9.4155e-01,  6.2700e-02,\n",
      "          6.0825e-02,  5.7044e-02,  6.0110e-02,  6.4846e-02,  6.2386e-02,\n",
      "         -1.0134e-01,  4.8157e-01,  6.4993e-02,  7.1605e-03,  6.2020e-02,\n",
      "          6.2424e-02,  6.9011e-02,  4.6987e-02,  4.6492e-02,  6.2751e-02],\n",
      "        [-1.6083e+01, -1.6084e+01, -5.3979e+00, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -8.5687e+00, -1.6085e+01, -1.6085e+01, -1.6084e+01,\n",
      "         -2.9299e+00, -1.6085e+01, -1.4670e+01, -1.6085e+01, -9.0825e+00,\n",
      "         -1.6078e+01, -1.6085e+01, -9.8232e+00, -1.6078e+01, -1.6085e+01,\n",
      "         -1.6076e+01, -1.0951e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6074e+01, -1.6085e+01, -1.6084e+01, -1.0636e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6084e+01, -1.6083e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.4680e+01, -1.4053e+01, -1.6082e+01, -1.6042e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6084e+01, -1.6078e+01, -1.6077e+01, -1.6085e+01]]) tensor([1, 1])\n",
      "tensor([[ 5.3033e-02,  5.3380e-02, -1.3805e-02,  6.1487e-02,  6.2018e-02,\n",
      "          6.1813e-02,  6.2235e-02,  6.3347e-02,  5.6586e-02,  6.1945e-02,\n",
      "          5.7336e-02, -9.7243e-01,  6.7089e-02,  5.7450e-02,  7.2649e-02,\n",
      "          2.0188e-01,  6.3359e-02, -5.2585e-02,  6.1781e-02,  3.9299e-02,\n",
      "          7.9400e-02,  6.3935e-02,  5.9228e-01,  5.0811e-02,  6.2558e-02,\n",
      "          8.1421e-02,  7.4281e-01,  6.1410e-02,  6.1776e-02,  6.3557e-02,\n",
      "          3.8173e-02,  6.5781e-02,  5.8706e-02,  9.4155e-01,  6.2700e-02,\n",
      "          6.0825e-02,  5.7044e-02,  6.0110e-02,  6.4846e-02,  6.2386e-02,\n",
      "         -1.0134e-01,  4.8157e-01,  6.4993e-02,  7.1605e-03,  6.2020e-02,\n",
      "          6.2424e-02,  6.9011e-02,  4.6987e-02,  4.6492e-02,  6.2751e-02],\n",
      "        [-1.6083e+01, -1.6084e+01, -5.3979e+00, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -8.5687e+00, -1.6085e+01, -1.6085e+01, -1.6084e+01,\n",
      "         -2.9299e+00, -1.6085e+01, -1.4670e+01, -1.6085e+01, -9.0825e+00,\n",
      "         -1.6078e+01, -1.6085e+01, -9.8232e+00, -1.6078e+01, -1.6085e+01,\n",
      "         -1.6076e+01, -1.0951e+01, -1.6085e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.6074e+01, -1.6085e+01, -1.6084e+01, -1.0636e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6084e+01, -1.6083e+01, -1.6085e+01, -1.6085e+01,\n",
      "         -1.4680e+01, -1.4053e+01, -1.6082e+01, -1.6042e+01, -1.6085e+01,\n",
      "         -1.6085e+01, -1.6084e+01, -1.6078e+01, -1.6077e+01, -1.6085e+01]]) tensor([42.0100, 76.0100]) tensor([20.0100,  1.0100])\n"
     ]
    }
   ],
   "source": [
    "### MiniBoo\n",
    "\n",
    "## choose random inducing points\n",
    "#X_MiniBoo_train_induced, y_MiniBoo_train_induced = classification_utils.random_inducing_points(X_MiniBoo_train, y_MiniBoo_train, NUM_INDUCING_POINTS_MiniBoo)\n",
    "\n",
    "## use kmeans for inducing points\n",
    "X_MiniBoo_train_induced, y_MiniBoo_train_induced = classification_utils.k_means_inducing_points(X_MiniBoo_train, y_MiniBoo_train, NUM_INDUCING_POINTS_MiniBoo)\n",
    "print(X_MiniBoo_train_induced[:2], y_MiniBoo_train_induced[:2])\n",
    "\n",
    "# use the conjugacy of the Beta to create better inducing points\n",
    "X_MiniBoo_train_induced, y_MiniBoo_train_induced_alphas, y_MiniBoo_train_induced_betas = classification_utils.k_means_inducing_points_LM_beta(X_MiniBoo_train, y_MiniBoo_train, NUM_INDUCING_POINTS_MiniBoo)\n",
    "print(X_MiniBoo_train_induced[:2], y_MiniBoo_train_induced_alphas[:2], y_MiniBoo_train_induced_betas[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for GPC & LB(Beta)+GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTHSCALES = [0.01, 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose lengthscale with CV\n",
    "NUM_ITER_EEG = 200\n",
    "LR_EEG = 0.1\n",
    "\"\"\"\n",
    "res_EEG = classification_models.select_init_lengthscale_with_CV(X_EEG_train, y_EEG_train, mode=\"DGP\",\n",
    "                                    num_inducing_points=NUM_INDUCING_POINTS_EEG, \n",
    "                                    learn_noise=True, num_iter=NUM_ITER_EEG, lr=LR_EEG,\n",
    "                                    lengthscales=LENGTHSCALES)\n",
    "print(res_EEG)    \n",
    "classification_utils.plot_res(res_EEG)\n",
    "\"\"\"\n",
    "\n",
    "INIT_LENGHTSCALE_EEG = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 5.967   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 5.355   lengthscale: 1.102   noise: 2.084\n",
      "Iter 41/200 - Loss: 5.152   lengthscale: 0.907   noise: 3.340\n",
      "Iter 61/200 - Loss: 5.130   lengthscale: 0.989   noise: 3.917\n",
      "Iter 81/200 - Loss: 5.127   lengthscale: 1.017   noise: 4.145\n",
      "Iter 101/200 - Loss: 5.127   lengthscale: 1.037   noise: 4.224\n",
      "Iter 121/200 - Loss: 5.126   lengthscale: 1.048   noise: 4.244\n",
      "Iter 141/200 - Loss: 5.126   lengthscale: 1.052   noise: 4.241\n",
      "Iter 161/200 - Loss: 5.126   lengthscale: 1.056   noise: 4.228\n",
      "Iter 181/200 - Loss: 5.126   lengthscale: 1.059   noise: 4.212\n",
      "(0.6467499732971191, 0.7012051939964294, 0.12777778506278992)\n"
     ]
    }
   ],
   "source": [
    "### run Dirichlet GPC\n",
    "\n",
    "DGP_model, DGP_likelihood = classification_models.create_DGP_model(X_EEG_train_induced, y_EEG_train_induced,\n",
    "                                        init_lengthscale=INIT_LENGHTSCALE_EEG, learn_additional_noise=True)\n",
    "DGP_model, DGP_likelihood = classification_models.train_DGP_model(X_EEG_train_induced,\n",
    "                                DGP_model, DGP_likelihood, num_iter=NUM_ITER_EEG, lr=LR_EEG, report_iter=NUM_ITER_EEG//10)\n",
    "EEG_DGP_res = classification_models.evaluate_DGP(DGP_model, DGP_likelihood, X_EEG_test, y_EEG_test)\n",
    "print(EEG_DGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 3.040   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.966   lengthscale: 1.035   noise: 2.124\n",
      "Iter 41/200 - Loss: 2.933   lengthscale: 1.307   noise: 3.780\n",
      "Iter 61/200 - Loss: 2.921   lengthscale: 1.448   noise: 5.039\n",
      "Iter 81/200 - Loss: 2.917   lengthscale: 1.507   noise: 5.896\n",
      "Iter 101/200 - Loss: 2.915   lengthscale: 1.562   noise: 6.477\n",
      "Iter 121/200 - Loss: 2.914   lengthscale: 1.605   noise: 6.876\n",
      "Iter 141/200 - Loss: 2.913   lengthscale: 1.639   noise: 7.149\n",
      "Iter 161/200 - Loss: 2.913   lengthscale: 1.665   noise: 7.332\n",
      "Iter 181/200 - Loss: 2.913   lengthscale: 1.685   noise: 7.451\n",
      "(0.606249988079071, 0.7131885290145874, 0.14380775392055511)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP vanilla\n",
    "y_EEG_train_induced_mu, y_EEG_train_induced_var = classification_models.transform_y_beta_LM(y_EEG_train_induced)\n",
    "LMGP_model_EEG, LMGP_likelihood_EEG = classification_models.create_LM_beta_GP_model(X_EEG_train_induced, y_EEG_train_induced_mu,\n",
    "                                                y_EEG_train_induced_var, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_EEG)\n",
    "LMGP_model_EEG, LMGP_likelihood_EEG = classification_models.train_LM_beta_GP_model(X_EEG_train_induced, y_EEG_train_induced_mu,\n",
    "                    LMGP_model_EEG, LMGP_likelihood_EEG, num_iter=NUM_ITER_EEG, lr=LR_EEG, report_iter=NUM_ITER_EEG//10)\n",
    "EEG_LMGP_res = classification_models.evaluate_LM_beta_GP(LMGP_model_EEG, LMGP_likelihood_EEG, X_EEG_test, y_EEG_test)\n",
    "print(EEG_LMGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.350   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.278   lengthscale: 1.174   noise: 1.206\n",
      "Iter 41/200 - Loss: 2.211   lengthscale: 0.792   noise: 0.435\n",
      "Iter 61/200 - Loss: 2.179   lengthscale: 0.729   noise: 0.131\n",
      "Iter 81/200 - Loss: 2.169   lengthscale: 0.730   noise: 0.083\n",
      "Iter 101/200 - Loss: 2.164   lengthscale: 0.748   noise: 0.071\n",
      "Iter 121/200 - Loss: 2.161   lengthscale: 0.760   noise: 0.066\n",
      "Iter 141/200 - Loss: 2.159   lengthscale: 0.771   noise: 0.064\n",
      "Iter 161/200 - Loss: 2.158   lengthscale: 0.781   noise: 0.063\n",
      "Iter 181/200 - Loss: 2.157   lengthscale: 0.789   noise: 0.063\n",
      "(0.7127500176429749, 0.5398080348968506, 0.021660421043634415)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP with conjugacy information\n",
    "\n",
    "train_mu_LB_con_EEG, train_var_LB_con_EEG = classification_models.LM_beta(y_EEG_train_induced_alphas, y_EEG_train_induced_betas)\n",
    "LMGP_model_con_EEG, LMGP_likelihood_con_EEG = classification_models.create_LM_beta_GP_model(X_EEG_train_induced, train_mu_LB_con_EEG,\n",
    "                                                train_var_LB_con_EEG, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_EEG)\n",
    "LMGP_model_con_EEG, LMGP_likelihood_con_EEG = classification_models.train_LM_beta_GP_model(X_EEG_train_induced, train_mu_LB_con_EEG,\n",
    "                LMGP_model_con_EEG, LMGP_likelihood_con_EEG, num_iter=NUM_ITER_EEG, lr=LR_EEG, report_iter=NUM_ITER_EEG//10)\n",
    "\n",
    "EEG_LMGP_con_res = classification_models.evaluate_LM_beta_GP(LMGP_model_con_EEG, LMGP_likelihood_con_EEG, X_EEG_test, y_EEG_test)\n",
    "print(EEG_LMGP_con_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTRU2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose lengthscale with CV\n",
    "NUM_ITER_HTRU2 = 200\n",
    "LR_HTRU2 = 0.1\n",
    "\"\"\"\n",
    "res_HTRU2 = classification_models.select_init_lengthscale_with_CV(X_HTRU2_train, y_HTRU2_train, mode=\"DGP\",\n",
    "                                    num_inducing_points=NUM_INDUCING_POINTS_HTRU2, \n",
    "                                    learn_noise=True, num_iter=NUM_ITER_HTRU2, lr=LR_HTRU2,\n",
    "                                    lengthscales=LENGTHSCALES)\n",
    "print(res_HTRU2)    \n",
    "classification_utils.plot_res(res_HTRU2)\n",
    "\"\"\"\n",
    "\n",
    "INIT_LENGHTSCALE_HTRU2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 4.444   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 3.501   lengthscale: 3.426   noise: 0.159\n",
      "Iter 41/200 - Loss: 3.397   lengthscale: 3.851   noise: 0.115\n",
      "Iter 61/200 - Loss: 3.368   lengthscale: 3.877   noise: 0.091\n",
      "Iter 81/200 - Loss: 3.356   lengthscale: 3.854   noise: 0.055\n",
      "Iter 101/200 - Loss: 3.349   lengthscale: 3.871   noise: 0.039\n",
      "Iter 121/200 - Loss: 3.345   lengthscale: 3.922   noise: 0.031\n",
      "Iter 141/200 - Loss: 3.343   lengthscale: 3.976   noise: 0.027\n",
      "Iter 161/200 - Loss: 3.341   lengthscale: 4.021   noise: 0.024\n",
      "Iter 181/200 - Loss: 3.339   lengthscale: 4.061   noise: 0.022\n",
      "(0.9782000184059143, 0.07795679569244385, 0.03839163854718208)\n"
     ]
    }
   ],
   "source": [
    "### run Dirichlet GPC\n",
    "\n",
    "DGP_model, DGP_likelihood = classification_models.create_DGP_model(X_HTRU2_train_induced, y_HTRU2_train_induced,\n",
    "                                        init_lengthscale=INIT_LENGHTSCALE_HTRU2, learn_additional_noise=True)\n",
    "DGP_model, DGP_likelihood = classification_models.train_DGP_model(X_HTRU2_train_induced,\n",
    "                                DGP_model, DGP_likelihood, num_iter=NUM_ITER_HTRU2, lr=LR_HTRU2, report_iter=NUM_ITER_HTRU2//10)\n",
    "HTRU2_DGP_res = classification_models.evaluate_DGP(DGP_model, DGP_likelihood, X_HTRU2_test, y_HTRU2_test)\n",
    "print(HTRU2_DGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.599   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.381   lengthscale: 3.525   noise: 0.137\n",
      "Iter 41/200 - Loss: 2.347   lengthscale: 4.105   noise: 0.042\n",
      "Iter 61/200 - Loss: 2.336   lengthscale: 4.172   noise: 0.022\n",
      "Iter 81/200 - Loss: 2.330   lengthscale: 4.140   noise: 0.015\n",
      "Iter 101/200 - Loss: 2.326   lengthscale: 4.136   noise: 0.012\n",
      "Iter 121/200 - Loss: 2.324   lengthscale: 4.165   noise: 0.009\n",
      "Iter 141/200 - Loss: 2.322   lengthscale: 4.205   noise: 0.008\n",
      "Iter 161/200 - Loss: 2.321   lengthscale: 4.244   noise: 0.006\n",
      "Iter 181/200 - Loss: 2.319   lengthscale: 4.280   noise: 0.005\n",
      "(0.9768000245094299, 0.0793921947479248, 0.039690300822257996)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP vanilla\n",
    "y_HTRU2_train_induced_mu, y_HTRU2_train_induced_var = classification_models.transform_y_beta_LM(y_HTRU2_train_induced)\n",
    "LMGP_model_HTRU2, LMGP_likelihood_HTRU2 = classification_models.create_LM_beta_GP_model(X_HTRU2_train_induced, y_HTRU2_train_induced_mu,\n",
    "                                                y_HTRU2_train_induced_var, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_HTRU2)\n",
    "LMGP_model_HTRU2, LMGP_likelihood_HTRU2 = classification_models.train_LM_beta_GP_model(X_HTRU2_train_induced, y_HTRU2_train_induced_mu,\n",
    "                    LMGP_model_HTRU2, LMGP_likelihood_HTRU2, num_iter=NUM_ITER_HTRU2, lr=LR_HTRU2, report_iter=NUM_ITER_HTRU2//10)\n",
    "HTRU2_LMGP_res = classification_models.evaluate_LM_beta_GP(LMGP_model_HTRU2, LMGP_likelihood_HTRU2, X_HTRU2_test, y_HTRU2_test)\n",
    "print(HTRU2_LMGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.620   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.252   lengthscale: 3.407   noise: 0.161\n",
      "Iter 41/200 - Loss: 2.191   lengthscale: 3.578   noise: 0.088\n",
      "Iter 61/200 - Loss: 2.163   lengthscale: 3.290   noise: 0.066\n",
      "Iter 81/200 - Loss: 2.149   lengthscale: 3.210   noise: 0.045\n",
      "Iter 101/200 - Loss: 2.139   lengthscale: 3.267   noise: 0.032\n",
      "Iter 121/200 - Loss: 2.132   lengthscale: 3.289   noise: 0.024\n",
      "Iter 141/200 - Loss: 2.127   lengthscale: 3.308   noise: 0.019\n",
      "Iter 161/200 - Loss: 2.123   lengthscale: 3.335   noise: 0.016\n",
      "Iter 181/200 - Loss: 2.119   lengthscale: 3.358   noise: 0.013\n",
      "(0.9796000123023987, 0.07123546302318573, 0.04246756061911583)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP with conjugacy information\n",
    "\n",
    "train_mu_LB_con_HTRU2, train_var_LB_con_HTRU2 = classification_models.LM_beta(y_HTRU2_train_induced_alphas, y_HTRU2_train_induced_betas)\n",
    "LMGP_model_con_HTRU2, LMGP_likelihood_con_HTRU2 = classification_models.create_LM_beta_GP_model(X_HTRU2_train_induced, train_mu_LB_con_HTRU2,\n",
    "                                                train_var_LB_con_HTRU2, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_HTRU2)\n",
    "LMGP_model_con_HTRU2, LMGP_likelihood_con_HTRU2 = classification_models.train_LM_beta_GP_model(X_HTRU2_train_induced, train_mu_LB_con_HTRU2,\n",
    "                LMGP_model_con_HTRU2, LMGP_likelihood_con_HTRU2, num_iter=NUM_ITER_HTRU2, lr=LR_HTRU2, report_iter=NUM_ITER_HTRU2//10)\n",
    "\n",
    "HTRU2_LMGP_con_res = classification_models.evaluate_LM_beta_GP(LMGP_model_con_HTRU2, LMGP_likelihood_con_HTRU2, X_HTRU2_test, y_HTRU2_test)\n",
    "print(HTRU2_LMGP_con_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose lengthscale with CV\n",
    "NUM_ITER_MAGIC = 200\n",
    "LR_MAGIC = 0.1\n",
    "\"\"\"\n",
    "res_MAGIC = classification_models.select_init_lengthscale_with_CV(X_MAGIC_train, y_MAGIC_train, mode=\"DGP\",\n",
    "                                    num_inducing_points=NUM_INDUCING_POINTS_MAGIC, \n",
    "                                    learn_noise=True, num_iter=NUM_ITER_MAGIC, lr=LR_MAGIC,\n",
    "                                    lengthscales=LENGTHSCALES)\n",
    "print(res_MAGIC)    \n",
    "classification_utils.plot_res(res_MAGIC)\n",
    "\"\"\"\n",
    "\n",
    "INIT_LENGHTSCALE_MAGIC = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 5.675   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 4.719   lengthscale: 3.013   noise: 1.796\n",
      "Iter 41/200 - Loss: 4.619   lengthscale: 3.311   noise: 1.784\n",
      "Iter 61/200 - Loss: 4.587   lengthscale: 3.351   noise: 1.436\n",
      "Iter 81/200 - Loss: 4.569   lengthscale: 3.196   noise: 1.342\n",
      "Iter 101/200 - Loss: 4.555   lengthscale: 3.070   noise: 1.307\n",
      "Iter 121/200 - Loss: 4.545   lengthscale: 2.936   noise: 1.245\n",
      "Iter 141/200 - Loss: 4.538   lengthscale: 2.823   noise: 1.188\n",
      "Iter 161/200 - Loss: 4.533   lengthscale: 2.735   noise: 1.152\n",
      "Iter 181/200 - Loss: 4.531   lengthscale: 2.687   noise: 1.131\n",
      "(0.795799970626831, 0.5362366437911987, 0.10130868852138519)\n"
     ]
    }
   ],
   "source": [
    "### run Dirichlet GPC\n",
    "\n",
    "DGP_model, DGP_likelihood = classification_models.create_DGP_model(X_MAGIC_train_induced, y_MAGIC_train_induced,\n",
    "                                        init_lengthscale=INIT_LENGHTSCALE_MAGIC, learn_additional_noise=True)\n",
    "DGP_model, DGP_likelihood = classification_models.train_DGP_model(X_MAGIC_train_induced,\n",
    "                                DGP_model, DGP_likelihood, num_iter=NUM_ITER_MAGIC, lr=LR_MAGIC, report_iter=NUM_ITER_MAGIC//10)\n",
    "MAGIC_DGP_res = classification_models.evaluate_DGP(DGP_model, DGP_likelihood, X_MAGIC_test, y_MAGIC_test)\n",
    "print(MAGIC_DGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.925   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.733   lengthscale: 3.253   noise: 1.609\n",
      "Iter 41/200 - Loss: 2.684   lengthscale: 2.736   noise: 0.876\n",
      "Iter 61/200 - Loss: 2.667   lengthscale: 2.743   noise: 0.263\n",
      "Iter 81/200 - Loss: 2.659   lengthscale: 2.752   noise: 0.116\n",
      "Iter 101/200 - Loss: 2.656   lengthscale: 2.794   noise: 0.072\n",
      "Iter 121/200 - Loss: 2.653   lengthscale: 2.815   noise: 0.052\n",
      "Iter 141/200 - Loss: 2.652   lengthscale: 2.845   noise: 0.040\n",
      "Iter 161/200 - Loss: 2.651   lengthscale: 2.869   noise: 0.032\n",
      "Iter 181/200 - Loss: 2.650   lengthscale: 2.891   noise: 0.026\n",
      "(0.7932000160217285, 0.49166595935821533, 0.08232767879962921)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP vanilla\n",
    "y_MAGIC_train_induced_mu, y_MAGIC_train_induced_var = classification_models.transform_y_beta_LM(y_MAGIC_train_induced)\n",
    "LMGP_model_MAGIC, LMGP_likelihood_MAGIC = classification_models.create_LM_beta_GP_model(X_MAGIC_train_induced, y_MAGIC_train_induced_mu,\n",
    "                                                y_MAGIC_train_induced_var, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_MAGIC)\n",
    "LMGP_model_MAGIC, LMGP_likelihood_MAGIC = classification_models.train_LM_beta_GP_model(X_MAGIC_train_induced, y_MAGIC_train_induced_mu,\n",
    "                    LMGP_model_MAGIC, LMGP_likelihood_MAGIC, num_iter=NUM_ITER_MAGIC, lr=LR_MAGIC, report_iter=NUM_ITER_MAGIC//10)\n",
    "MAGIC_LMGP_res = classification_models.evaluate_LM_beta_GP(LMGP_model_MAGIC, LMGP_likelihood_MAGIC, X_MAGIC_test, y_MAGIC_test)\n",
    "print(MAGIC_LMGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.124   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 1.675   lengthscale: 3.445   noise: 0.139\n",
      "Iter 41/200 - Loss: 1.615   lengthscale: 3.478   noise: 0.048\n",
      "Iter 61/200 - Loss: 1.602   lengthscale: 3.340   noise: 0.028\n",
      "Iter 81/200 - Loss: 1.598   lengthscale: 3.473   noise: 0.020\n",
      "Iter 101/200 - Loss: 1.595   lengthscale: 3.522   noise: 0.016\n",
      "Iter 121/200 - Loss: 1.593   lengthscale: 3.563   noise: 0.013\n",
      "Iter 141/200 - Loss: 1.592   lengthscale: 3.608   noise: 0.011\n",
      "Iter 161/200 - Loss: 1.591   lengthscale: 3.643   noise: 0.009\n",
      "Iter 181/200 - Loss: 1.591   lengthscale: 3.675   noise: 0.008\n",
      "(0.8162000179290771, 0.40867048501968384, 0.04362637922167778)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP with conjugacy information\n",
    "\n",
    "train_mu_LB_con_MAGIC, train_var_LB_con_MAGIC = classification_models.LM_beta(y_MAGIC_train_induced_alphas, y_MAGIC_train_induced_betas)\n",
    "LMGP_model_con_MAGIC, LMGP_likelihood_con_MAGIC = classification_models.create_LM_beta_GP_model(X_MAGIC_train_induced, train_mu_LB_con_MAGIC,\n",
    "                                                train_var_LB_con_MAGIC, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_MAGIC)\n",
    "LMGP_model_con_MAGIC, LMGP_likelihood_con_MAGIC = classification_models.train_LM_beta_GP_model(X_MAGIC_train_induced, train_mu_LB_con_MAGIC,\n",
    "                LMGP_model_con_MAGIC, LMGP_likelihood_con_MAGIC, num_iter=NUM_ITER_MAGIC, lr=LR_MAGIC, report_iter=NUM_ITER_MAGIC//10)\n",
    "\n",
    "MAGIC_LMGP_con_res = classification_models.evaluate_LM_beta_GP(LMGP_model_con_MAGIC, LMGP_likelihood_con_MAGIC, X_MAGIC_test, y_MAGIC_test)\n",
    "print(MAGIC_LMGP_con_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiniBoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose lengthscale with CV\n",
    "NUM_ITER_MiniBoo = 200\n",
    "LR_MiniBoo = 0.1\n",
    "\"\"\"\n",
    "res_MiniBoo = classification_models.select_init_lengthscale_with_CV(X_MiniBoo_train, y_MiniBoo_train, mode=\"DGP\",\n",
    "                                    num_inducing_points=NUM_INDUCING_POINTS_MiniBoo, \n",
    "                                    learn_noise=True, num_iter=NUM_ITER_MiniBoo, lr=LR_MiniBoo,\n",
    "                                    lengthscales=LENGTHSCALES)\n",
    "print(res_MiniBoo)    \n",
    "classification_utils.plot_res(res_MiniBoo)\n",
    "\"\"\"\n",
    "\n",
    "INIT_LENGHTSCALE_MiniBoo = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 4.973   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 4.445   lengthscale: 2.704   noise: 1.299\n",
      "Iter 41/200 - Loss: 4.388   lengthscale: 2.939   noise: 0.970\n",
      "Iter 61/200 - Loss: 4.370   lengthscale: 2.887   noise: 0.978\n",
      "Iter 81/200 - Loss: 4.356   lengthscale: 2.688   noise: 0.887\n",
      "Iter 101/200 - Loss: 4.333   lengthscale: 2.338   noise: 0.727\n",
      "Iter 121/200 - Loss: 4.309   lengthscale: 1.943   noise: 0.611\n",
      "Iter 141/200 - Loss: 4.305   lengthscale: 1.931   noise: 0.595\n",
      "Iter 161/200 - Loss: 4.303   lengthscale: 1.973   noise: 0.591\n",
      "Iter 181/200 - Loss: 4.302   lengthscale: 1.964   noise: 0.590\n",
      "(0.866599977016449, 0.33838561177253723, 0.029760224744677544)\n"
     ]
    }
   ],
   "source": [
    "### run Dirichlet GPC\n",
    "\n",
    "DGP_model, DGP_likelihood = classification_models.create_DGP_model(X_MiniBoo_train_induced, y_MiniBoo_train_induced,\n",
    "                                        init_lengthscale=INIT_LENGHTSCALE_MiniBoo, learn_additional_noise=True)\n",
    "DGP_model, DGP_likelihood = classification_models.train_DGP_model(X_MiniBoo_train_induced,\n",
    "                                DGP_model, DGP_likelihood, num_iter=NUM_ITER_MiniBoo, lr=LR_MiniBoo, report_iter=NUM_ITER_MiniBoo//10)\n",
    "MiniBoo_DGP_res = classification_models.evaluate_DGP(DGP_model, DGP_likelihood, X_MiniBoo_test, y_MiniBoo_test)\n",
    "print(MiniBoo_DGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.755   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 2.610   lengthscale: 2.559   noise: 0.278\n",
      "Iter 41/200 - Loss: 2.579   lengthscale: 2.291   noise: 0.058\n",
      "Iter 61/200 - Loss: 2.571   lengthscale: 2.344   noise: 0.025\n",
      "Iter 81/200 - Loss: 2.567   lengthscale: 2.389   noise: 0.016\n",
      "Iter 101/200 - Loss: 2.564   lengthscale: 2.391   noise: 0.012\n",
      "Iter 121/200 - Loss: 2.563   lengthscale: 2.409   noise: 0.009\n",
      "Iter 141/200 - Loss: 2.562   lengthscale: 2.427   noise: 0.007\n",
      "Iter 161/200 - Loss: 2.561   lengthscale: 2.441   noise: 0.006\n",
      "Iter 181/200 - Loss: 2.561   lengthscale: 2.455   noise: 0.005\n",
      "(0.8677999973297119, 0.3311293423175812, 0.012597399763762951)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP vanilla\n",
    "y_MiniBoo_train_induced_mu, y_MiniBoo_train_induced_var = classification_models.transform_y_beta_LM(y_MiniBoo_train_induced)\n",
    "LMGP_model_MiniBoo, LMGP_likelihood_MiniBoo = classification_models.create_LM_beta_GP_model(X_MiniBoo_train_induced, y_MiniBoo_train_induced_mu,\n",
    "                                                y_MiniBoo_train_induced_var, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_MiniBoo)\n",
    "LMGP_model_MiniBoo, LMGP_likelihood_MiniBoo = classification_models.train_LM_beta_GP_model(X_MiniBoo_train_induced, y_MiniBoo_train_induced_mu,\n",
    "                    LMGP_model_MiniBoo, LMGP_likelihood_MiniBoo, num_iter=NUM_ITER_MiniBoo, lr=LR_MiniBoo, report_iter=NUM_ITER_MiniBoo//10)\n",
    "MiniBoo_LMGP_res = classification_models.evaluate_LM_beta_GP(LMGP_model_MiniBoo, LMGP_likelihood_MiniBoo, X_MiniBoo_test, y_MiniBoo_test)\n",
    "print(MiniBoo_LMGP_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 2.059   lengthscale: 2.000   noise: 0.693\n",
      "Iter 21/200 - Loss: 1.892   lengthscale: 2.156   noise: 0.162\n",
      "Iter 41/200 - Loss: 1.870   lengthscale: 2.274   noise: 0.093\n",
      "Iter 61/200 - Loss: 1.864   lengthscale: 2.337   noise: 0.092\n",
      "Iter 81/200 - Loss: 1.861   lengthscale: 2.394   noise: 0.098\n",
      "Iter 101/200 - Loss: 1.860   lengthscale: 2.441   noise: 0.100\n",
      "Iter 121/200 - Loss: 1.859   lengthscale: 2.470   noise: 0.099\n",
      "Iter 141/200 - Loss: 1.858   lengthscale: 2.496   noise: 0.098\n",
      "Iter 161/200 - Loss: 1.858   lengthscale: 2.518   noise: 0.097\n",
      "Iter 181/200 - Loss: 1.857   lengthscale: 2.536   noise: 0.097\n",
      "(0.8726000189781189, 0.2973827123641968, 0.02488512359559536)\n"
     ]
    }
   ],
   "source": [
    "### Run LM(Beta)+GP with conjugacy information\n",
    "\n",
    "train_mu_LB_con_MiniBoo, train_var_LB_con_MiniBoo = classification_models.LM_beta(y_MiniBoo_train_induced_alphas, y_MiniBoo_train_induced_betas)\n",
    "LMGP_model_con_MiniBoo, LMGP_likelihood_con_MiniBoo = classification_models.create_LM_beta_GP_model(X_MiniBoo_train_induced, train_mu_LB_con_MiniBoo,\n",
    "                                                train_var_LB_con_MiniBoo, learn_additional_noise=True,\n",
    "                                               init_lengthscale=INIT_LENGHTSCALE_MiniBoo)\n",
    "LMGP_model_con_MiniBoo, LMGP_likelihood_con_MiniBoo = classification_models.train_LM_beta_GP_model(X_MiniBoo_train_induced, train_mu_LB_con_MiniBoo,\n",
    "                LMGP_model_con_MiniBoo, LMGP_likelihood_con_MiniBoo, num_iter=NUM_ITER_MiniBoo, lr=LR_MiniBoo, report_iter=NUM_ITER_MiniBoo//10)\n",
    "\n",
    "MiniBoo_LMGP_con_res = classification_models.evaluate_LM_beta_GP(LMGP_model_con_MiniBoo, LMGP_likelihood_con_MiniBoo, X_MiniBoo_test, y_MiniBoo_test)\n",
    "print(MiniBoo_LMGP_con_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = {\n",
    "    \"EEG_res\":{\n",
    "        \"DGP\":list(EEG_DGP_res), \n",
    "        \"LMGP\":list(EEG_LMGP_res), \n",
    "        \"LMGP_con\":list(EEG_LMGP_con_res)\n",
    "    },\n",
    "    \"HTRU2_res\":{\n",
    "        \"DGP\":list(HTRU2_DGP_res), \n",
    "        \"LMGP\":list(HTRU2_LMGP_res), \n",
    "        \"LMGP_con\":list(HTRU2_LMGP_con_res)\n",
    "    },\n",
    "    \"MAGIC_res\":{\n",
    "        \"DGP\":list(MAGIC_DGP_res), \n",
    "        \"LMGP\":list(MAGIC_LMGP_res), \n",
    "        \"LMGP_con\":list(MAGIC_LMGP_con_res)\n",
    "    },\n",
    "    \"MiniBoo_res\":{\n",
    "        \"DGP\":list(MiniBoo_DGP_res), \n",
    "        \"LMGP\":list(MiniBoo_LMGP_res), \n",
    "        \"LMGP_con\":list(MiniBoo_LMGP_con_res)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EEG_res': {'DGP': [0.6467499732971191, 0.7012051939964294, 0.12777778506278992], 'LMGP': [0.606249988079071, 0.7131885290145874, 0.14380775392055511], 'LMGP_con': [0.7127500176429749, 0.5398080348968506, 0.021660421043634415]}, 'HTRU2_res': {'DGP': [0.9782000184059143, 0.07795679569244385, 0.03839163854718208], 'LMGP': [0.9768000245094299, 0.0793921947479248, 0.039690300822257996], 'LMGP_con': [0.9796000123023987, 0.07123546302318573, 0.04246756061911583]}, 'MAGIC_res': {'DGP': [0.795799970626831, 0.5362366437911987, 0.10130868852138519], 'LMGP': [0.7932000160217285, 0.49166595935821533, 0.08232767879962921], 'LMGP_con': [0.8162000179290771, 0.40867048501968384, 0.04362637922167778]}, 'MiniBoo_res': {'DGP': [0.866599977016449, 0.33838561177253723, 0.029760224744677544], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(all_res)\n",
    "#save results for this seed\n",
    "\n",
    "res_file = open(\"results/bin_class_seed_{}.json\".format(seed), \"w\")\n",
    "json.dump(all_res, res_file)\n",
    "res_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-36-6aaf1f276005>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-6aaf1f276005>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EEG_res': {'DGP': [0.5885000228881836, 0.7486024498939514, 0.17264671623706818], 'LMGP': [0.5569999814033508, 0.729259729385376, 0.09519588202238083], 'LMGP_con': [0.6862499713897705, 0.5671086311340332, 0.013570543378591537]}, 'HTRU2_res': {'DGP': [0.9779999852180481, 0.07645564526319504, 0.039890140295028687], 'LMGP': [0.977400004863739, 0.07888096570968628, 0.039150871336460114], 'LMGP_con': [0.9797999858856201, 0.07336153835058212, 0.04176821559667587]}, 'MAGIC_res': {'DGP': [0.7919999957084656, 0.6402088403701782, 0.1169930025935173], 'LMGP': [0.7914000153541565, 0.552958607673645, 0.09899098426103592], 'LMGP_con': [0.824999988079071, 0.4007170796394348, 0.05011987313628197]}, 'MiniBoo_res': {'DGP': [0.8668000102043152, 0.33881834149360657, 0.029520491138100624], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n",
      "{'EEG_res': {'DGP': [0.6362500190734863, 0.6315459609031677, 0.0551435723900795], 'LMGP': [0.578000009059906, 0.6621639132499695, 0.07444444298744202], 'LMGP_con': [0.6955000162124634, 0.5480953454971313, 0.021535592153668404]}, 'HTRU2_res': {'DGP': [0.9733999967575073, 0.09256896376609802, 0.038171835243701935], 'LMGP': [0.9721999764442444, 0.08989989757537842, 0.03927072510123253], 'LMGP_con': [0.9751999974250793, 0.0848274752497673, 0.037392597645521164]}, 'MAGIC_res': {'DGP': [0.8011999726295471, 0.5869053602218628, 0.09643355011940002], 'LMGP': [0.7937999963760376, 0.5216696262359619, 0.08734266459941864], 'LMGP_con': [0.8212000131607056, 0.4114838242530823, 0.04946053400635719]}, 'MiniBoo_res': {'DGP': [0.8664000034332275, 0.3383502960205078, 0.029980000108480453], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n",
      "{'EEG_res': {'DGP': [0.5872499942779541, 0.7239165902137756, 0.13644194602966309], 'LMGP': [0.5852500200271606, 0.6865164041519165, 0.10098625719547272], 'LMGP_con': [0.6875, 0.5505354404449463, 0.019013741984963417]}, 'HTRU2_res': {'DGP': [0.9739999771118164, 0.09063036739826202, 0.03817182406783104], 'LMGP': [0.9715999960899353, 0.09093181788921356, 0.037572432309389114], 'LMGP_con': [0.975600004196167, 0.07962378114461899, 0.03939061611890793]}, 'MAGIC_res': {'DGP': [0.7968000173568726, 0.553565263748169, 0.10956043750047684], 'LMGP': [0.7990000247955322, 0.4814997911453247, 0.07971030473709106], 'LMGP_con': [0.8235999941825867, 0.40687790513038635, 0.047222789376974106]}, 'MiniBoo_res': {'DGP': [0.8669999837875366, 0.338272362947464, 0.02952045202255249], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n",
      "{'EEG_res': {'DGP': [0.6807500123977661, 0.6890937685966492, 0.10687888413667679], 'LMGP': [0.671999990940094, 0.6624484658241272, 0.07404493540525436], 'LMGP_con': [0.6875, 0.548423171043396, 0.02717852033674717]}, 'HTRU2_res': {'DGP': [0.9764000177383423, 0.08670683950185776, 0.0359540618956089], 'LMGP': [0.973800003528595, 0.08550375699996948, 0.04116884991526604], 'LMGP_con': [0.9783999919891357, 0.07691948115825653, 0.0431668646633625]}, 'MAGIC_res': {'DGP': [0.800599992275238, 0.5621601343154907, 0.10818183422088623], 'LMGP': [0.7993999719619751, 0.4891148507595062, 0.0902397632598877], 'LMGP_con': [0.8334000110626221, 0.38137179613113403, 0.06030968576669693]}, 'MiniBoo_res': {'DGP': [0.8669999837875366, 0.3374374210834503, 0.02936064451932907], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n",
      "{'EEG_res': {'DGP': [0.6467499732971191, 0.7012051939964294, 0.12777778506278992], 'LMGP': [0.606249988079071, 0.7131885290145874, 0.14380775392055511], 'LMGP_con': [0.7127500176429749, 0.5398080348968506, 0.021660421043634415]}, 'HTRU2_res': {'DGP': [0.9782000184059143, 0.07795679569244385, 0.03839163854718208], 'LMGP': [0.9768000245094299, 0.0793921947479248, 0.039690300822257996], 'LMGP_con': [0.9796000123023987, 0.07123546302318573, 0.04246756061911583]}, 'MAGIC_res': {'DGP': [0.795799970626831, 0.5362366437911987, 0.10130868852138519], 'LMGP': [0.7932000160217285, 0.49166595935821533, 0.08232767879962921], 'LMGP_con': [0.8162000179290771, 0.40867048501968384, 0.04362637922167778]}, 'MiniBoo_res': {'DGP': [0.866599977016449, 0.33838561177253723, 0.029760224744677544], 'LMGP': [0.8677999973297119, 0.3311293423175812, 0.012597399763762951], 'LMGP_con': [0.8726000189781189, 0.2973827123641968, 0.02488512359559536]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "### over all seeds\n",
    "\n",
    "DGP_acc_all = []\n",
    "LMGP_acc_all = []\n",
    "LMGP_con_acc_all = []\n",
    "DGP_mnll_all = []\n",
    "LMGP_mnll_all = []\n",
    "LMGP_con_mnll_all = []\n",
    "DGP_ece_all = []\n",
    "LMGP_ece_all = []\n",
    "LMGP_con_ece_all = []\n",
    "\n",
    "for seed in range(5):\n",
    "    seed +=1\n",
    "\n",
    "    with open('results/bin_class_seed_{}.json'.format(seed)) as json_file:\n",
    "        all_res = json.load(json_file)\n",
    "    print(all_res)\n",
    "\n",
    "    DGP_acc = []\n",
    "    LMGP_acc = []\n",
    "    LMGP_con_acc = []\n",
    "    DGP_mnll = []\n",
    "    LMGP_mnll = []\n",
    "    LMGP_con_mnll = []\n",
    "    DGP_ece = []\n",
    "    LMGP_ece = []\n",
    "    LMGP_con_ece = []\n",
    "\n",
    "    for dataset in [\"EEG_res\", \"HTRU2_res\", \"MAGIC_res\", \"MiniBoo_res\"]:\n",
    "\n",
    "        DGP_acc.append(all_res[dataset][\"DGP\"][0])\n",
    "        LMGP_acc.append(all_res[dataset][\"LMGP\"][0])\n",
    "        LMGP_con_acc.append(all_res[dataset][\"LMGP_con\"][0])\n",
    "        DGP_mnll.append(all_res[dataset][\"DGP\"][1])\n",
    "        LMGP_mnll.append(all_res[dataset][\"LMGP\"][1])\n",
    "        LMGP_con_mnll.append(all_res[dataset][\"LMGP_con\"][1])\n",
    "        DGP_ece.append(all_res[dataset][\"DGP\"][2])\n",
    "        LMGP_ece.append(all_res[dataset][\"LMGP\"][2])\n",
    "        LMGP_con_ece.append(all_res[dataset][\"LMGP_con\"][2])\n",
    "        \n",
    "    DGP_acc_all.append(DGP_acc)\n",
    "    LMGP_acc_all.append(LMGP_acc)\n",
    "    LMGP_con_acc_all.append(LMGP_con_acc)\n",
    "    DGP_mnll_all.append(DGP_mnll)\n",
    "    LMGP_mnll_all.append(LMGP_mnll)\n",
    "    LMGP_con_mnll_all.append(LMGP_con_mnll)\n",
    "    DGP_ece_all.append(DGP_ece)\n",
    "    LMGP_ece_all.append(LMGP_ece)\n",
    "    LMGP_con_ece_all.append(LMGP_con_ece)\n",
    "    \n",
    "DGP_acc_mean = np.array(DGP_acc_all).mean(0)\n",
    "LMGP_acc_mean = np.array(LMGP_acc_all).mean(0)\n",
    "LMGP_con_acc_mean = np.array(LMGP_con_acc_all).mean(0)\n",
    "DGP_mnll_mean = np.array(DGP_mnll_all).mean(0)\n",
    "LMGP_mnll_mean = np.array(LMGP_mnll_all).mean(0)\n",
    "LMGP_con_mnll_mean = np.array(LMGP_con_mnll_all).mean(0)\n",
    "DGP_ece_mean = np.array(DGP_ece_all).mean(0)\n",
    "LMGP_ece_mean = np.array(LMGP_ece_all).mean(0)\n",
    "LMGP_con_ece_mean = np.array(LMGP_con_ece_all).mean(0)\n",
    "\n",
    "DGP_acc_std = np.array(DGP_acc_all).std(0)\n",
    "LMGP_acc_std = np.array(LMGP_acc_all).std(0)\n",
    "LMGP_con_acc_std = np.array(LMGP_con_acc_all).std(0)\n",
    "DGP_mnll_std = np.array(DGP_mnll_all).std(0)\n",
    "LMGP_mnll_std = np.array(LMGP_mnll_all).std(0)\n",
    "LMGP_con_mnll_std = np.array(LMGP_con_mnll_all).std(0)\n",
    "DGP_ece_std = np.array(DGP_ece_all).std(0)\n",
    "LMGP_ece_std = np.array(LMGP_ece_all).std(0)\n",
    "LMGP_con_ece_std = np.array(LMGP_con_ece_all).std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-8c970ba05a43>:32: UserWarning: This figure was using constrained_layout==True, but that is incompatible with subplots_adjust and or tight_layout: setting constrained_layout==False. \n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1100x849.797 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "w=0.23\n",
    "c=0.25\n",
    "x=np.arange(4)\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(figwidth, 2.5*figheight), dpi=200, sharex=True)\n",
    "\n",
    "ax[0].bar(x-1*c, DGP_acc_mean, width=w, yerr=2*DGP_acc_std, color=\"firebrick\", label=\"DGP\")\n",
    "ax[0].bar(x, LMGP_acc_mean, width=w, yerr=2*LMGP_acc_std, color=\"cornflowerblue\", label=\"LM(Beta)+GP\")\n",
    "ax[0].bar(x+1*c, LMGP_con_acc_mean, width=w, yerr=2*LMGP_con_acc_std, color=\"orange\", label=\"LM(Beta)+GP+conjugacy\")\n",
    "ax[0].grid()\n",
    "ax[0].set_ylim(0, 1.05)\n",
    "ax[0].set_ylabel(u\"Accuracy \\u2192\")\n",
    "#ax[0].legend()\n",
    "\n",
    "ax[1].bar(x-1*c, DGP_mnll_mean, width=w, yerr=2*DGP_mnll_std, color=\"firebrick\", label=\"DGP\")\n",
    "ax[1].bar(x, LMGP_mnll_mean, width=w, yerr=2*LMGP_mnll_std, color=\"cornflowerblue\", label=\"LM(Beta)+GP\")\n",
    "ax[1].bar(x+1*c, LMGP_con_mnll_mean, width=w, yerr=2*LMGP_con_mnll_std, color=\"orange\", label=\"LM(Beta)+GP+conjugacy\")\n",
    "ax[1].grid()\n",
    "ax[1].set_ylabel(u\"MNLL \\u2190\")\n",
    "\n",
    "ax[2].bar(x-1*c, DGP_ece_mean, width=w, yerr=2*DGP_ece_std, color=\"firebrick\", label=\"DGP\")\n",
    "ax[2].bar(x, LMGP_ece_mean, width=w, yerr=2*LMGP_ece_std, color=\"cornflowerblue\", label=\"LM(Beta)+GP\")\n",
    "ax[2].bar(x+1*c, LMGP_con_ece_mean, width=w, yerr=2*LMGP_con_ece_std, color=\"orange\", label=\"LM(Beta)+GP+conjugacy\")\n",
    "ax[2].grid()\n",
    "ax[2].set_ylabel(u\"ECE \\u2190\")\n",
    "ax[2].legend()\n",
    "\n",
    "ax[2].set_xticks(x)\n",
    "ax[2].set_xticklabels([\"EEG\", \"HTRU2\", \"MAGIC\", \"MiniBoo\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/bin_class_results.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
